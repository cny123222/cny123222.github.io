

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Nuoyan Chen">
  <meta name="keywords" content="">
  
    <meta name="description" content="本文将精读 GNN4CO 代码，代码来自 RethinkLab 的 ML4CO-Bench-101 仓库，具体代码见 https:&#x2F;&#x2F;github.com&#x2F;Thinklab-SJTU&#x2F;ML4CO-Bench-101&#x2F;tree&#x2F;main&#x2F;ml4co&#x2F;gnn4co。">
<meta property="og:type" content="article">
<meta property="og:title" content="Code Reading #1: GNN4CO">
<meta property="og:url" content="https://cny123222.github.io/2025/08/24/Code-Reading-1-GNN4CO/index.html">
<meta property="og:site_name" content="Nuoyan Chen&#39;s Blog">
<meta property="og:description" content="本文将精读 GNN4CO 代码，代码来自 RethinkLab 的 ML4CO-Bench-101 仓库，具体代码见 https:&#x2F;&#x2F;github.com&#x2F;Thinklab-SJTU&#x2F;ML4CO-Bench-101&#x2F;tree&#x2F;main&#x2F;ml4co&#x2F;gnn4co。">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://cny123222.github.io/img/ml4co.png">
<meta property="article:published_time" content="2025-08-24T14:29:10.000Z">
<meta property="article:modified_time" content="2025-11-06T02:39:24.119Z">
<meta property="article:author" content="Nuoyan Chen">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="ML4CO">
<meta property="article:tag" content="Code Reading">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://cny123222.github.io/img/ml4co.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>Code Reading #1: GNN4CO - Nuoyan Chen&#39;s Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/KaTeX/0.16.2/katex.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"cny123222.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":3},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 80vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Nuoyan Chen&#39;s Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>Categories</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>Tags</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/" target="_self">
                <i class="iconfont icon-link-fill"></i>
                <span>Links</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/nanjing.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.4)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Code Reading #1: GNN4CO"></span>
          
        </div>

        
          
  <div class="mt-3">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-author" aria-hidden="true"></i>
        Nuoyan Chen
      </span>
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-08-24 22:29" pubdate>
          August 24, 2025 pm
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          14k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          116 mins
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> views
        </span>
        

      
    
  </div>


        
      </div>

      
        <div class="scroll-down-bar">
          <i class="iconfont icon-arrowdown"></i>
        </div>
      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar category-bar" style="margin-right: -1rem">
    





<div class="category-list">
  
  
    
    
    
    <div class="category row nomargin-x">
      <a class="category-item 
          list-group-item category-item-action col-10 col-md-11 col-xm-11" title="ML4CO"
        id="heading-f96b490a324eb7ddf9240b3448b5a7a7" role="tab" data-toggle="collapse" href="#collapse-f96b490a324eb7ddf9240b3448b5a7a7"
        aria-expanded="true"
      >
        ML4CO
        <span class="list-group-count">(17)</span>
        <i class="iconfont icon-arrowright"></i>
      </a>
      
      <div class="category-collapse collapse show" id="collapse-f96b490a324eb7ddf9240b3448b5a7a7"
           role="tabpanel" aria-labelledby="heading-f96b490a324eb7ddf9240b3448b5a7a7">
        
        
          
          
  <div class="category-post-list">
    
    
      
      
        <a href="/2025/07/25/A-Living-Guide-to-ML4CO/" title="A Living Guide to ML4CO"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">A Living Guide to ML4CO</span>
        </a>
      
    
  </div>

          
  
    
    
    
    <div class="category-sub row nomargin-x">
      <a class="category-subitem collapsed
          list-group-item category-item-action col-10 col-md-11 col-xm-11" title="Basics"
        id="heading-bbc9105ee8508ce6e083a589a351e83a" role="tab" data-toggle="collapse" href="#collapse-bbc9105ee8508ce6e083a589a351e83a"
        aria-expanded="false"
      >
        Basics
        <span class="list-group-count">(6)</span>
        <i class="iconfont icon-arrowright"></i>
      </a>
      
      <div class="category-collapse collapse " id="collapse-bbc9105ee8508ce6e083a589a351e83a"
           role="tabpanel" aria-labelledby="heading-bbc9105ee8508ce6e083a589a351e83a">
        
        
          
  <div class="category-post-list">
    
    
      
      
        <a href="/2025/07/28/Common-CO-Problems-in-ML4CO/" title="Common CO Problems in ML4CO"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Common CO Problems in ML4CO</span>
        </a>
      
    
      
      
        <a href="/2025/07/27/Paradigm-1-Supervised-GNN-Decoding/" title="Paradigm 1: Supervised GNN + Decoding"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Paradigm 1: Supervised GNN + Decoding</span>
        </a>
      
    
      
      
        <a href="/2025/08/01/Paradigm-2-Autoregressive-Transformer-RL/" title="Paradigm 2: Autoregressive Transformer + RL"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Paradigm 2: Autoregressive Transformer + RL</span>
        </a>
      
    
      
      
        <a href="/2025/07/28/Traditional-Solver-Baselines-in-ML4CO/" title="Traditional Solver Baselines in ML4CO"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Traditional Solver Baselines in ML4CO</span>
        </a>
      
    
      
      
        <a href="/2025/07/26/Understading-GNN-An-ML4CO-perspective/" title="Understading GNN - An ML4CO perspective"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Understading GNN - An ML4CO perspective</span>
        </a>
      
    
      
      
        <a href="/2025/08/01/Understading-Transformer-An-ML4CO-perspective/" title="Understading Transformer - An ML4CO perspective"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Understading Transformer - An ML4CO perspective</span>
        </a>
      
    
  </div>

        
      </div>
    </div>
  
    
    
    
    <div class="category-sub row nomargin-x">
      <a class="category-subitem 
          list-group-item category-item-action col-10 col-md-11 col-xm-11" title="Code Reading"
        id="heading-f77e38c01e2888b0c14a4f2e5ee3be87" role="tab" data-toggle="collapse" href="#collapse-f77e38c01e2888b0c14a4f2e5ee3be87"
        aria-expanded="true"
      >
        Code Reading
        <span class="list-group-count">(1)</span>
        <i class="iconfont icon-arrowright"></i>
      </a>
      
      <div class="category-collapse collapse show" id="collapse-f77e38c01e2888b0c14a4f2e5ee3be87"
           role="tabpanel" aria-labelledby="heading-f77e38c01e2888b0c14a4f2e5ee3be87">
        
        
          
  <div class="category-post-list">
    
    
      
      
        <a href="/2025/08/24/Code-Reading-1-GNN4CO/" title="Code Reading #1: GNN4CO"
           class="list-group-item list-group-item-action
           active">
          <span class="category-post">Code Reading #1: GNN4CO</span>
        </a>
      
    
  </div>

        
      </div>
    </div>
  
    
    
    
    <div class="category-sub row nomargin-x">
      <a class="category-subitem collapsed
          list-group-item category-item-action col-10 col-md-11 col-xm-11" title="Paper Reading"
        id="heading-717502770b97d51394e7c55fa4354d40" role="tab" data-toggle="collapse" href="#collapse-717502770b97d51394e7c55fa4354d40"
        aria-expanded="false"
      >
        Paper Reading
        <span class="list-group-count">(9)</span>
        <i class="iconfont icon-arrowright"></i>
      </a>
      
      <div class="category-collapse collapse " id="collapse-717502770b97d51394e7c55fa4354d40"
           role="tabpanel" aria-labelledby="heading-717502770b97d51394e7c55fa4354d40">
        
        
          
  <div class="category-post-list">
    
    
      
      
        <a href="/2025/07/30/Paper-Reading-1-GCN4TSP/" title="Paper Reading #1: GCN4TSP"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Paper Reading #1: GCN4TSP</span>
        </a>
      
    
      
      
        <a href="/2025/07/30/Paper-Reading-2-AM/" title="Paper Reading #2: AM"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Paper Reading #2: AM</span>
        </a>
      
    
      
      
        <a href="/2025/08/18/Paper-Reading-3-RL4VRP/" title="Paper Reading #3: RL4VRP"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Paper Reading #3: RL4VRP</span>
        </a>
      
    
      
      
        <a href="/2025/08/19/Paper-Reading-4-POMO/" title="Paper Reading #4: POMO"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Paper Reading #4: POMO</span>
        </a>
      
    
      
      
        <a href="/2025/08/23/Paper-Reading-5-MatNet/" title="Paper Reading #5: MatNet"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Paper Reading #5: MatNet</span>
        </a>
      
    
      
      
        <a href="/2025/08/28/Paper-Reading-6-SymNCO/" title="Paper Reading #6: SymNCO"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Paper Reading #6: SymNCO</span>
        </a>
      
    
      
      
        <a href="/2025/10/28/Paper-Reading-7-DIMES/" title="Paper Reading #7: DIMES"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Paper Reading #7: DIMES</span>
        </a>
      
    
      
      
        <a href="/2025/10/28/Paper-Reading-8-DIFUSCO/" title="Paper Reading #8: DIFUSCO"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Paper Reading #8: DIFUSCO</span>
        </a>
      
    
      
      
        <a href="/2025/10/29/Paper-Reading-9-T2T/" title="Paper Reading #9: T2T"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Paper Reading #9: T2T</span>
        </a>
      
    
  </div>

        
      </div>
    </div>
  
        
      </div>
    </div>
  
</div>


  </aside>


    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">Code Reading #1: GNN4CO</h1>
            
              <p id="updated-time" class="note note-default" style="">
                
                  
                    Last updated on November 6, 2025 am
                  
                
              </p>
            
            
              <div class="markdown-body">
                
                <p>本文将精读 GNN4CO 代码，代码来自 RethinkLab 的 ML4CO-Bench-101 仓库，具体代码见 <a target="_blank" rel="noopener" href="https://github.com/Thinklab-SJTU/ML4CO-Bench-101/tree/main/ml4co/gnn4co">https://github.com/Thinklab-SJTU/ML4CO-Bench-101/tree/main/ml4co/gnn4co</a>。</p>
<span id="more"></span>
<h2 id="引言">引言</h2>
<p>为了更好地进行 ML4CO 方向的研究，我们应该熟悉 ML4CO 的具体代码，<strong>能看懂代码逻辑和实现方法</strong>，并按照自己的需求进行修改。<a target="_blank" rel="noopener" href="https://github.com/Thinklab-SJTU/ML4CO-Bench-101">ML4CO-Bench-101</a> 是 Rethinklab 的一个 github 仓库，其中整合了诸多经典的 ML4CO 方法的代码实现。<strong>我们将以 ML4CO-Bench-101 中的代码作为分析的素材。</strong></p>
<p>一般来说，一个大项目的代码都会比较庞大，一句句理解非常困难。我们将<strong>遵循从宏观到微观的阅读方法</strong>，先了解每块代码的作用，再针对性分析重点的语句。</p>
<h2 id="整体框架">整体框架</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">.<br>├── __init__.py<br>├── env<br>│   ├── __init__.py<br>│   ├── dense<br>│   │   ├── __init__.py<br>│   │   ├── atsp.py<br>│   │   ├── cvrp.py<br>│   │   └── tsp.py<br>│   ├── denser.py<br>│   ├── env.py<br>│   ├── sparse<br>│   │   ├── __init__.py<br>│   │   ├── atsp.py<br>│   │   ├── cvrp.py<br>│   │   ├── mcl.py<br>│   │   ├── mcut.py<br>│   │   ├── mis.py<br>│   │   ├── mvc.py<br>│   │   └── tsp.py<br>│   └── sparser.py<br>├── model<br>│   ├── __init__.py<br>│   ├── decoder<br>│   │   ├── __init__.py<br>│   │   ├── atsp.py<br>│   │   ├── base.py<br>│   │   ├── mcl.py<br>│   │   ├── mcut.py<br>│   │   ├── mis.py<br>│   │   ├── mvc.py<br>│   │   └── tsp.py<br>│   ├── embedder<br>│   │   ├── __init__.py<br>│   │   ├── atsp.py<br>│   │   ├── base.py<br>│   │   ├── cvrp.py<br>│   │   ├── mcl.py<br>│   │   ├── mcut.py<br>│   │   ├── mis.py<br>│   │   ├── mvc.py<br>│   │   ├── tsp.py<br>│   │   └── utils.py<br>│   ├── encoder<br>│   │   ├── __init__.py<br>│   │   ├── gnn_encoder.py<br>│   │   ├── gnn_encoder_tsp.py<br>│   │   ├── gnn_layer.py<br>│   │   └── gnn_layer_tsp.py<br>│   ├── model.py<br>│   └── out_layer<br>│       ├── __init__.py<br>│       ├── base.py<br>│       ├── edge.py<br>│       ├── node.py<br>│       └── utils.py<br>└── solver<br>    ├── __init__.py<br>    ├── atsp.py<br>    ├── mcl.py<br>    ├── mcut.py<br>    ├── mis.py<br>    ├── mvc.py<br>    └── tsp.py<br></code></pre></td></tr></table></figure>
<p>可以看到，GNN4CO 的代码整体分为 <code>env</code>、<code>model</code> 和 <code>solver</code> 三部分。这三部分各自的功能是：</p>
<ul>
<li><code>env</code>：负责数据集的生成和加载。</li>
<li><code>model</code>：核心模型，包含 <code>Encoder</code> 和 <code>Decoder</code>，并需要 <code>Env</code> 来生成训练和验证数据。</li>
<li><code>solver</code>：求解器，用于 test 阶段，会调用训练好的 <code>Model</code> 进行测试。</li>
</ul>
<pre><code class=" mermaid">graph TD;
  subgraph &quot;train&quot;
    A[Trainer] --&gt; B[Model];
    B --&gt; C[Env];
    B --&gt; D[Encoder];
    B --&gt; E[Decoder];
    C --&gt; G[Denser];
    C --&gt; H[Sparser];
    D --&gt; I[Embedder];
    D --&gt; K[DenseBlock];
    D --&gt; L[SparseBlock];
    K --&gt; M[DenseLayer];
    L --&gt; N[SparseLayer];
    D --&gt; J[OutLayer];
  end
  subgraph &quot;test&quot;
    F[Solver] --&gt; B;
  end
</code></pre>
<p>这是代码中关键的 class 之间的调用关系。<strong>训练时</strong>，我们调用 Pytorch Lightning 库中的 <code>Trainer</code> 来训练 <code>Model</code>；<strong>测试时</strong>，我们调用 <code>Solver</code> 来对 <code>Model</code> 进行测试。</p>
<p>需要说明的是，<strong>sparse 和 dense 分别表示图的稀疏表示和稠密表示</strong>。在稀疏表示中，我们保存每条边连接的两个顶点编号，即图的边表表示；在稠密表示中，我们记录每一对顶点之间是否有边，即图的邻接矩阵表示。</p>
<h2 id="Env">Env</h2>
<p><code>Env</code> 为训练、验证和测试提供数据，主要包括了<strong>数据的读取与解析、数据的格式转换、数据的批供给</strong>等功能。核心的类是 <code>GNN4COEnv</code>，它从文件中读取各种 CO 问题的原始数据，将其转换为适应 GNN 的格式（支持稠密图和稀疏图），为模型的训练、验证和测试提供一批批处理好的数据。</p>
<h3 id="env-py"><code>env.py</code></h3>
<p><code>env.py</code> 中首先定义了一个 <code>FakeDataset</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">FakeDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, data_size: <span class="hljs-built_in">int</span></span>):<br>        <span class="hljs-variable language_">self</span>.data_size = data_size<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.data_size<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx: <span class="hljs-built_in">int</span></span>):<br>        <span class="hljs-keyword">return</span> torch.tensor([idx])<br></code></pre></td></tr></table></figure>
<p>这是一个辅助性的<strong>伪数据集</strong>，本身不包含任何真实数据，只实现了最基本的方法。这里定义的 <code>FakeDataset</code> 会被放入 <code>train_dataloader</code>、<code>val_dataloader</code> 和 <code>test_dataloader</code>。Pytorch Lightning 框架会自动将数据做成 batch，传递给 <code>Model</code> 的训练、验证和测试函数。但这里，我们并不实际用这个数据的传递路径，而是直接在 <code>Model</code> 中通过调用 <code>Env</code> 提供的方法来加载数据。原因是可以更加灵活，按照需要读取数据，不用一次性读入。</p>
<p>接下来，我们看核心的 <code>GNN4COEnv</code> 类。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">GNN4COEnv</span>(<span class="hljs-title class_ inherited__">BaseEnv</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        task: <span class="hljs-built_in">str</span> = <span class="hljs-literal">None</span>,  <span class="hljs-comment"># &quot;TSP&quot;, &quot;MIS&quot;, etc.</span></span><br><span class="hljs-params">        mode: <span class="hljs-built_in">str</span> = <span class="hljs-literal">None</span>,  <span class="hljs-comment"># &quot;train&quot;, &quot;val&quot;, &quot;solve&quot;</span></span><br><span class="hljs-params">        train_data_size: <span class="hljs-built_in">int</span> = <span class="hljs-number">128000</span>,</span><br><span class="hljs-params">        val_data_size: <span class="hljs-built_in">int</span> = <span class="hljs-number">128</span>,</span><br><span class="hljs-params">        train_batch_size: <span class="hljs-built_in">int</span> = <span class="hljs-number">4</span>,</span><br><span class="hljs-params">        val_batch_size: <span class="hljs-built_in">int</span> = <span class="hljs-number">4</span>,</span><br><span class="hljs-params">        num_workers: <span class="hljs-built_in">int</span> = <span class="hljs-number">4</span>,</span><br><span class="hljs-params">        sparse_factor: <span class="hljs-built_in">int</span> = <span class="hljs-number">50</span>,</span><br><span class="hljs-params">        device: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;cpu&quot;</span>,</span><br><span class="hljs-params">        train_folder: <span class="hljs-built_in">str</span> = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        val_path: <span class="hljs-built_in">str</span> = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        store_data: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">True</span>,</span><br><span class="hljs-params">    </span>):<br>        <span class="hljs-built_in">super</span>().__init__(<br>            name=<span class="hljs-string">&quot;GNN4COEnv&quot;</span>,<br>            mode=mode,<br>            train_batch_size=train_batch_size,<br>            val_batch_size=val_batch_size,<br>            num_workers=num_workers,<br>            device=device<br>        )<br>        <br>        <span class="hljs-comment"># basic</span><br>        <span class="hljs-variable language_">self</span>.task = task<br>        <span class="hljs-variable language_">self</span>.sparse = sparse_factor &gt; <span class="hljs-number">0</span><br>        <span class="hljs-variable language_">self</span>.sparse_factor = sparse_factor<br>        <br>        <span class="hljs-comment"># train data folder and val path</span><br>        <span class="hljs-variable language_">self</span>.train_folder = train_folder<br>        <span class="hljs-variable language_">self</span>.val_path = val_path<br>        <br>        <span class="hljs-comment"># ml4co-kit solver</span><br>        <span class="hljs-variable language_">self</span>.atsp_solver = ATSPSolver()<br>        <span class="hljs-variable language_">self</span>.cvrp_solver = CVRPSolver()<br>        <span class="hljs-variable language_">self</span>.mcl_solver = MClSolver()<br>        <span class="hljs-variable language_">self</span>.mcut_solver = MCutSolver()<br>        <span class="hljs-variable language_">self</span>.mis_solver = MISSolver()<br>        <span class="hljs-variable language_">self</span>.mvc_solver = MVCSolver()<br>        <span class="hljs-variable language_">self</span>.tsp_solver = TSPSolver()<br>        <br>        <span class="hljs-comment"># dataset (Fake)</span><br>        <span class="hljs-variable language_">self</span>.store_data = store_data<br>        <span class="hljs-variable language_">self</span>.train_dataset = FakeDataset(train_data_size)<br>        <span class="hljs-variable language_">self</span>.val_dataset = FakeDataset(val_data_size)<br>          <br>        <span class="hljs-comment"># data_processor (sparser and denser)</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.sparse:<br>            <span class="hljs-variable language_">self</span>.data_processor = GNN4COSparser(<span class="hljs-variable language_">self</span>.sparse_factor, <span class="hljs-variable language_">self</span>.device)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-variable language_">self</span>.data_processor = GNN4CODenser(<span class="hljs-variable language_">self</span>.device)<br>        <br>        <span class="hljs-comment"># load data</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.mode <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-variable language_">self</span>.load_data()<br></code></pre></td></tr></table></figure>
<p>主要看几个初始化参数：</p>
<ul>
<li><code>train_data_size</code> 和 <code>val_data_size</code>：训练和验证数据集的名义大小，仅用于创建 <code>FakeDataset</code>。</li>
<li><code>num_workers</code>：PyTorch <code>DataLoader</code> 使用的子进程数量，用于并行加载数据。</li>
<li><code>sparse_factor</code>：决定数据处理方式，如果 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">&gt; 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span>，则启用稀疏图模式；否则，使用稠密图模式。具体含义见后文。</li>
<li><code>train_folder</code>：包含多个训练数据文件的文件夹路径，训练模式必需。</li>
<li><code>val_path</code>：单个验证数据文件的路径，验证模式必需。</li>
<li><code>store_data</code>：是否在内存中缓存已加载的训练文件，以加速后续 epoch 的数据读取。具体后文介绍。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_data</span>(<span class="hljs-params">self</span>):<br>       <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.mode == <span class="hljs-string">&quot;train&quot;</span>:<br>           <span class="hljs-variable language_">self</span>.train_sub_files = [<br>               os.path.join(<span class="hljs-variable language_">self</span>.train_folder, train_files) \<br>                   <span class="hljs-keyword">for</span> train_files <span class="hljs-keyword">in</span> os.listdir(<span class="hljs-variable language_">self</span>.train_folder) <br>           ]<br>           <span class="hljs-variable language_">self</span>.train_sub_files_num = <span class="hljs-built_in">len</span>(<span class="hljs-variable language_">self</span>.train_sub_files)<br>           <span class="hljs-variable language_">self</span>.train_data_historty_cache = <span class="hljs-built_in">dict</span>()<br>           <span class="hljs-variable language_">self</span>.train_data_cache = <span class="hljs-literal">None</span><br>           <span class="hljs-variable language_">self</span>.val_data_cache = <span class="hljs-literal">None</span><br>           <span class="hljs-variable language_">self</span>.train_data_cache_idx = <span class="hljs-number">0</span><br>       <span class="hljs-keyword">else</span>:<br>           <span class="hljs-keyword">pass</span><br></code></pre></td></tr></table></figure>
<p><code>load_data()</code> 方法只有在训练模式下使用，<strong>为数据加载做准备工作</strong>。首先，扫描 <code>self.train_folder</code> 目录，获取所有训练数据文件的路径列表 <code>self.train_sub_files</code>。接着，初始化用于训练数据缓存的字典和变量，如 <code>self.train_data_historty_cache</code>（历史缓存，用于存储已加载过的整个文件）和 <code>self.train_data_cache</code>（当前缓存，存放当前正在使用的文件数据）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_dataloader</span>(<span class="hljs-params">self</span>):<br>       train_dataloader=DataLoader(<br>           <span class="hljs-variable language_">self</span>.train_dataset, <br>           batch_size=<span class="hljs-variable language_">self</span>.train_batch_size, <br>           shuffle=<span class="hljs-literal">True</span>,<br>           num_workers=<span class="hljs-variable language_">self</span>.num_workers, <br>           pin_memory=<span class="hljs-literal">True</span>,<br>           persistent_workers=<span class="hljs-literal">True</span>, <br>           drop_last=<span class="hljs-literal">True</span><br>       )<br>       <span class="hljs-keyword">return</span> train_dataloader<br></code></pre></td></tr></table></figure>
<p>（此处省略类似的 <code>val_dataloader()</code> 和 <code>test_dataloader()</code> 方法）</p>
<p><code>train_dataloader()</code>、<code>val_dataloader()</code> 和 <code>test_dataloader()</code> 方法被 PyTorch Lightning 调用，返回 <code>Dataloader</code> 对象。但注意，这个返回的 <code>Dataloader</code> 是 fake 的，其中只有索引而没有真实数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_val_data</span>(<span class="hljs-params">self, val_idx: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">Any</span>:<br>       begin_idx = val_idx * <span class="hljs-variable language_">self</span>.val_batch_size<br>       end_idx = begin_idx + <span class="hljs-variable language_">self</span>.val_batch_size<br>       <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.task == <span class="hljs-string">&quot;ATSP&quot;</span>:<br>           <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.generate_val_data_atsp(begin_idx, end_idx)<br>       <span class="hljs-keyword">elif</span> <span class="hljs-variable language_">self</span>.task == <span class="hljs-string">&quot;CVRP&quot;</span>:<br>           <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.generate_val_data_cvrp(begin_idx, end_idx)<br>       <span class="hljs-keyword">elif</span> <span class="hljs-variable language_">self</span>.task == <span class="hljs-string">&quot;MCl&quot;</span>:<br>           <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.generate_val_data_mcl(begin_idx, end_idx)<br>       <span class="hljs-keyword">elif</span> <span class="hljs-variable language_">self</span>.task == <span class="hljs-string">&quot;MCut&quot;</span>:<br>           <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.generate_val_data_mcut(begin_idx, end_idx)<br>       <span class="hljs-keyword">elif</span> <span class="hljs-variable language_">self</span>.task == <span class="hljs-string">&quot;MIS&quot;</span>:<br>           <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.generate_val_data_mis(begin_idx, end_idx)<br>       <span class="hljs-keyword">elif</span> <span class="hljs-variable language_">self</span>.task == <span class="hljs-string">&quot;MVC&quot;</span>:<br>           <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.generate_val_data_mvc(begin_idx, end_idx)<br>       <span class="hljs-keyword">elif</span> <span class="hljs-variable language_">self</span>.task == <span class="hljs-string">&quot;TSP&quot;</span>:<br>           <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.generate_val_data_tsp(begin_idx, end_idx) <br></code></pre></td></tr></table></figure>
<p><code>generate_val_data()</code> 方法是分发器，根据 <code>self.task</code> 调用具体的生成函数，这些生成函数就是真实产生数据的地方。<code>val_idx</code> 是批次序号，即需要第几批数据。根据这个序号及 <code>self.batch_size</code> 即可推算出这个批次的 <code>begin_idx</code> 和 <code>end_idx</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_val_data_tsp</span>(<span class="hljs-params">self, begin_idx: <span class="hljs-built_in">int</span>, end_idx: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">Any</span>:<br>       <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.val_data_cache <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>           <span class="hljs-variable language_">self</span>.tsp_solver.from_txt(<span class="hljs-variable language_">self</span>.val_path, ref=<span class="hljs-literal">True</span>)<br>           <span class="hljs-variable language_">self</span>.val_data_cache = &#123;<br>               <span class="hljs-string">&quot;points&quot;</span>: <span class="hljs-variable language_">self</span>.tsp_solver.points,<br>               <span class="hljs-string">&quot;ref_tours&quot;</span>: <span class="hljs-variable language_">self</span>.tsp_solver.ref_tours<br>           &#125;<br>       <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.data_processor.tsp_batch_data_process(<br>           points=<span class="hljs-variable language_">self</span>.val_data_cache[<span class="hljs-string">&quot;points&quot;</span>][begin_idx:end_idx], <br>           ref_tours=<span class="hljs-variable language_">self</span>.val_data_cache[<span class="hljs-string">&quot;ref_tours&quot;</span>][begin_idx:end_idx]<br>       )<br></code></pre></td></tr></table></figure>
<p>（此处省略 <code>generate_val_data_atsp</code> 等其他任务的类似函数）</p>
<p>接下来是一组 <code>generate_val_data_...()</code> 方法，作用是<strong>生成并处理一个批次的验证数据</strong>。这里以 <code>generate_val_data_tsp()</code> 为例。首先，检查 <code>self.val_data_cache</code> 是否为空。</p>
<ul>
<li><strong>如果为空</strong>：表明是第一次调用，它会调用 <code>self.tsp_solver</code> 的 <code>from_txt()</code> 方法，<strong>一次性将整个验证文件中的数据加载到内存中</strong>，并存入 <code>self.val_data_cache</code>。</li>
<li><strong>如果不为空</strong>：表示已经加载过数据，于是直接从内存中的 <code>self.val_data_cache</code> 根据 <code>begin_idx</code> 和 <code>end_idx</code> 切片出当前批次所需的数据。</li>
</ul>
<p>最后，将切片出的数据交给 <code>self.data_processor</code> 进行最终的格式转换，然后返回。格式转换的具体做法见后文。</p>
<p>其他 <code>generate_val_data_...()</code> 函数逻辑完全相同，只是调用的 solver 和 processor 方法不同。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_train_data</span>(<span class="hljs-params">self, batch_size: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">Any</span>:<br>       <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.task == <span class="hljs-string">&quot;ATSP&quot;</span>:<br>           <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.generate_train_data_atsp(batch_size)<br>       <span class="hljs-keyword">elif</span> <span class="hljs-variable language_">self</span>.task == <span class="hljs-string">&quot;CVRP&quot;</span>:<br>           <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.generate_train_data_cvrp(batch_size)<br>       <span class="hljs-keyword">elif</span> <span class="hljs-variable language_">self</span>.task == <span class="hljs-string">&quot;MCl&quot;</span>:<br>           <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.generate_train_data_mcl(batch_size)<br>       <span class="hljs-keyword">elif</span> <span class="hljs-variable language_">self</span>.task == <span class="hljs-string">&quot;MCut&quot;</span>:<br>           <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.generate_train_data_mcut(batch_size)<br>       <span class="hljs-keyword">elif</span> <span class="hljs-variable language_">self</span>.task == <span class="hljs-string">&quot;MIS&quot;</span>:<br>           <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.generate_train_data_mis(batch_size)<br>       <span class="hljs-keyword">elif</span> <span class="hljs-variable language_">self</span>.task == <span class="hljs-string">&quot;MVC&quot;</span>:<br>           <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.generate_train_data_mvc(batch_size)<br>       <span class="hljs-keyword">elif</span> <span class="hljs-variable language_">self</span>.task == <span class="hljs-string">&quot;TSP&quot;</span>:<br>           <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.generate_train_data_tsp(batch_size) <br></code></pre></td></tr></table></figure>
<p><code>generate_train_data()</code> 与 <code>generate_val_data()</code> 类似，但不计算 <code>begin_idx</code> 和 <code>end_idx</code>，具体在各个任务的方法中实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_train_data_tsp</span>(<span class="hljs-params">self, batch_size: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">Any</span>:<br>       <span class="hljs-comment"># check data cache</span><br>       begin_idx = <span class="hljs-variable language_">self</span>.train_data_cache_idx<br>       end_idx = begin_idx + batch_size<br>       <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.train_data_cache <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">or</span> end_idx &gt; <span class="hljs-variable language_">self</span>.train_data_cache[<span class="hljs-string">&quot;data_size&quot;</span>]:<br>           <span class="hljs-comment"># select one train file randomly</span><br>           sel_idx = np.random.randint(low=<span class="hljs-number">0</span>, high=<span class="hljs-variable language_">self</span>.train_sub_files_num, size=(<span class="hljs-number">1</span>,))[<span class="hljs-number">0</span>]<br>           sel_train_sub_file_path = <span class="hljs-variable language_">self</span>.train_sub_files[sel_idx]<br><br>           <span class="hljs-comment"># check if the data is in the cache when store_data is True</span><br>           <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.store_data <span class="hljs-keyword">and</span> sel_train_sub_file_path <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.train_data_historty_cache.keys():<br>               <span class="hljs-comment"># using data cache if the data is in the cache</span><br>               <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;\nusing data cache (<span class="hljs-subst">&#123;sel_train_sub_file_path&#125;</span>)&quot;</span>)<br>               <span class="hljs-variable language_">self</span>.train_data_cache = <span class="hljs-variable language_">self</span>.train_data_historty_cache[sel_train_sub_file_path]<br>           <span class="hljs-keyword">else</span>: <br>               <span class="hljs-comment"># load data from the train file</span><br>               <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;\nload tsp train data from <span class="hljs-subst">&#123;sel_train_sub_file_path&#125;</span>&quot;</span>)<br>               <span class="hljs-variable language_">self</span>.tsp_solver.from_txt(sel_train_sub_file_path, show_time=<span class="hljs-literal">True</span>, ref=<span class="hljs-literal">True</span>)<br>               <span class="hljs-variable language_">self</span>.train_data_cache = &#123;<br>                   <span class="hljs-string">&quot;points&quot;</span>: <span class="hljs-variable language_">self</span>.tsp_solver.points,<br>                   <span class="hljs-string">&quot;ref_tours&quot;</span>: <span class="hljs-variable language_">self</span>.tsp_solver.ref_tours,<br>                   <span class="hljs-string">&quot;data_size&quot;</span>: <span class="hljs-variable language_">self</span>.tsp_solver.points.shape[<span class="hljs-number">0</span>]<br>               &#125;<br>               <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.store_data:<br>                   <span class="hljs-variable language_">self</span>.train_data_historty_cache[sel_train_sub_file_path] = <span class="hljs-variable language_">self</span>.train_data_cache<br>           <br>           <span class="hljs-comment"># update cache and index</span><br>           <span class="hljs-variable language_">self</span>.train_data_cache_idx = <span class="hljs-number">0</span><br>           begin_idx = <span class="hljs-variable language_">self</span>.train_data_cache_idx<br>           end_idx = begin_idx + batch_size<br>   <br>       <span class="hljs-comment"># retrieve a portion of data from the cache</span><br>       points = <span class="hljs-variable language_">self</span>.train_data_cache[<span class="hljs-string">&quot;points&quot;</span>][begin_idx:end_idx]<br>       ref_tours = <span class="hljs-variable language_">self</span>.train_data_cache[<span class="hljs-string">&quot;ref_tours&quot;</span>][begin_idx:end_idx]<br>       <span class="hljs-variable language_">self</span>.train_data_cache_idx = end_idx<br>           <br>       <span class="hljs-comment"># data process</span><br>       <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.data_processor.tsp_batch_data_process(points, ref_tours)<br></code></pre></td></tr></table></figure>
<p>（此处省略 <code>generate_train_data_atsp</code> 等其他问题的类似函数）</p>
<p>接下来是一组 <code>generate_train_data_...()</code> 方法，作用是<strong>生成并处理一个批次的训练数据</strong>。<code>self.train_data_cache_idx</code> 中保存了下一条数据在 <code>self.train_data_cache</code> 中的序号，再由 <code>batch_size</code> 我们可以计算出这个批次的 <code>begin_idx</code> 和 <code>end_idx</code>。</p>
<ul>
<li>首先，检查 <code>self。train_data_cache</code> 中剩余的数据是否足够供应当前的 <code>batch_size</code>。</li>
<li>如果缓存不足（<code>end_idx &gt; self.train_data_cache[&quot;data_size&quot;]</code>）或者根本还没有缓存（<code>self.train_data_cache is None</code>），那么：
<ul>
<li>先从 <code>self.train_sub_files</code> 列表中随机挑选一个训练文件 <code>sel_train_sub_file_path</code>。</li>
<li>如果 <code>self.store_data</code> 是否为 <code>True</code>，即加载过的数据会被保存，那么继续检查这个随机选中的文件是否已经存在于 <code>self.train_data_historty_cache</code> 中。</li>
<li>如果存在，<strong>直接从内存中读取，避免了磁盘 I/O，提升了速度</strong>。</li>
<li>如果不存在，就只能从磁盘文件中加载。加载后，如果 <code>self.store_data</code> 为 <code>True</code>，会将其存入历史缓存中，供未来使用。</li>
<li>加载完新文件后，将 <code>self.train_data_cache_idx</code> 重置为 0。</li>
</ul>
</li>
<li>确认需要的数据已经在内存中后，从当前文件缓存 <code>self.train_data_cache</code> 中切片出当前批次的数据。接着，更新 <code>self.train_data_cache_idx</code>，指向下一批数据的起始位置。</li>
<li>最后，将切片出的数据交给 <code>self.data_processor</code> 处理后返回。</li>
</ul>
<h3 id="denser-py"><code>denser.py</code></h3>
<p><code>GNN4CODenser</code> 类是一个<strong>批处理转换器</strong>，接收一个批次 Numpy 格式的原始数据，并将它们转换成一个批次 PyTorch Tensor 格式的、适用于 GNN 模型的稠密图表示。稠密，即用<strong>邻接矩阵或距离矩阵</strong>来表示图的结构。在矩阵中，每个节点都与其他所有节点有一条边，矩阵的每个元素 <code>(i, j)</code> 代表了节点 <code>i</code> 和 <code>j</code> 之间的关系（如距离）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">GNN4CODenser</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, device: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-variable language_">self</span>.device = device<br></code></pre></td></tr></table></figure>
<p>构造函数，保存 device 属性。后续所有生成的 PyTorch Tensor 都将被移动到这个指定的设备上，以确保数据和模型在同一个设备上。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">initial_lists</span>(<span class="hljs-params">self</span>):<br>       <span class="hljs-variable language_">self</span>.nodes_feature_list = <span class="hljs-built_in">list</span>()<br>       <span class="hljs-variable language_">self</span>.x_list = <span class="hljs-built_in">list</span>()<br>       <span class="hljs-variable language_">self</span>.graph_list = <span class="hljs-built_in">list</span>()<br>       <span class="hljs-variable language_">self</span>.ground_truth_list = <span class="hljs-built_in">list</span>()<br>       <span class="hljs-variable language_">self</span>.nodes_num_list = <span class="hljs-built_in">list</span>()<br>       <br>   <span class="hljs-keyword">def</span> <span class="hljs-title function_">update_lists</span>(<span class="hljs-params">self, dense_data: <span class="hljs-type">Any</span></span>):<br>       <span class="hljs-variable language_">self</span>.x_list.append(dense_data[<span class="hljs-number">0</span>])<br>       <span class="hljs-variable language_">self</span>.graph_list.append(dense_data[<span class="hljs-number">1</span>])<br>       <span class="hljs-variable language_">self</span>.ground_truth_list.append(dense_data[<span class="hljs-number">2</span>])<br>       <span class="hljs-variable language_">self</span>.nodes_num_list.append(dense_data[<span class="hljs-number">3</span>])<br></code></pre></td></tr></table></figure>
<p>这是一对状态管理的辅助函数。<code>initial_lists()</code> 方法在处理一个新批次的最开始被调用，负责清空所有用于临时存储的列表。<code>update_lists()</code> 方法在循环中被反复调用，将每个处理好的数据实例（一个包含节点特征、图矩阵、真值等的元组）的各个部分分别追加到对应的列表中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">edge_merge_process</span>(<span class="hljs-params">self, task: <span class="hljs-built_in">str</span>, with_gt: <span class="hljs-built_in">bool</span></span>) -&gt; <span class="hljs-type">Any</span>:<br>       <span class="hljs-comment"># nodes feature</span><br>       <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.x_list[<span class="hljs-number">0</span>] <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>           x = torch.stack(<span class="hljs-variable language_">self</span>.x_list, <span class="hljs-number">0</span>).to(<span class="hljs-variable language_">self</span>.device)<br>       <span class="hljs-keyword">else</span>:<br>           x = <span class="hljs-literal">None</span><br>           <br>       <span class="hljs-comment"># graph</span><br>       graph = torch.stack(<span class="hljs-variable language_">self</span>.graph_list, <span class="hljs-number">0</span>).to(<span class="hljs-variable language_">self</span>.device)<br><br>       <span class="hljs-comment"># ground truth</span><br>       <span class="hljs-keyword">if</span> with_gt:<br>           ground_truth = torch.stack(<br>               <span class="hljs-variable language_">self</span>.ground_truth_list, <span class="hljs-number">0</span><br>           ).to(<span class="hljs-variable language_">self</span>.device) <span class="hljs-comment"># (B, V, V) or (B, V)</span><br>       <span class="hljs-keyword">else</span>:<br>           ground_truth = <span class="hljs-literal">None</span><br>       <br>       <span class="hljs-keyword">return</span> (task, x, graph, ground_truth, <span class="hljs-variable language_">self</span>.nodes_num_list) <br></code></pre></td></tr></table></figure>
<p><code>edge_merge_process()</code> 方法负责将收集到的数据列表打包成最终的批次化输出。</p>
<ul>
<li>节点特征 <code>x</code>：使用 <code>torch.stack(self.x_list, 0)</code> 将多个 <code>(V, D)</code> 形状的节点特征 Tensor 堆叠成一个 <code>(B, V, D)</code> 的批次张量（其中 <code>B</code> 是批大小，<code>V</code> 是节点数，<code>D</code> 是特征维度）。</li>
<li>图 <code>graph</code>：将多个 <code>(V, V)</code> 的邻接矩阵或距离矩阵堆叠成 <code>(B, V, V)</code> 的批次张量。</li>
<li>真值 <code>ground_truth</code>：如果 <code>with_gt</code> 为 <code>True</code>，则将真值（如最优路径）也堆叠成批次张量。</li>
</ul>
<p>所有创建的 Tensor 都被 <code>.to(self.device)</code> 移动到目标设备。最后，将所有处理好的数据打包成一个元组返回。<strong>这个元组就是 GNN 模型的最终输入。</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">tsp_batch_data_process</span>(<span class="hljs-params"></span><br><span class="hljs-params">       self, points: np.ndarray, ref_tours: np.ndarray, sampling_num: <span class="hljs-built_in">int</span> = <span class="hljs-number">1</span></span><br><span class="hljs-params">   </span>) -&gt; <span class="hljs-type">Any</span>:<br>       <span class="hljs-comment"># check dimension</span><br>       check_dim(points, <span class="hljs-number">3</span>)<br>       check_dim(ref_tours, <span class="hljs-number">2</span>)<br>       <br>       <span class="hljs-comment"># initialize lists</span><br>       <span class="hljs-variable language_">self</span>.initial_lists()<br>       <br>       <span class="hljs-comment"># dense process</span><br>       <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(points.shape[<span class="hljs-number">0</span>]):<br>           dense_data = tsp_dense_process(<br>               points=points[idx], <br>               ref_tour=ref_tours[idx] <span class="hljs-keyword">if</span> ref_tours <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>, <br>           )<br>           <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(sampling_num):<br>               <span class="hljs-variable language_">self</span>.update_lists(dense_data)<br>       <br>       <span class="hljs-comment"># merge</span><br>       <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.edge_merge_process(<br>           task=<span class="hljs-string">&quot;TSP&quot;</span>, <br>           with_gt=<span class="hljs-literal">True</span> <span class="hljs-keyword">if</span> ref_tours <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">False</span><br>       )<br></code></pre></td></tr></table></figure>
<p>（此处省略 <code>atsp_batch_data_process</code> 等其他问题的类似函数）</p>
<p>注意，<strong>只有选边问题（ATSP、CVRP、TSP）进行了稠密图实现</strong>，选点问题没有稠密图实现。这一系列函数是<strong>供外部调用的数据处理核心函数</strong>。</p>
<p>我们此处以 TSP 的对应方法为例。首先，检查输入维度，并调用 <code>initial_lists()</code> 方法重置状态。接着，遍历批次中的每一个问题实例，通过调用了 <code>tsp_dense_process()</code> 方法来处理单个 TSP 实例，并将单个实例的处理结果存入列表中。如果 <code>sampling_num</code> 大于 1，同一个处理好的实例会被重复添加到列表中多次，用于数据增强。最后，调用 <code>edge_merge_process()</code> 完成最后的打包工作，并返回结果。</p>
<h3 id="dense"><code>dense</code></h3>
<p>我们接着看<strong>单个实例的格式转换</strong>。这些函数位于 <code>dense</code> 文件夹中，用于接收单个实例的 Numpy 格式的原始数据，并将其转换成 PyTorch Tensor 格式的、适用于 GNN 模型的<strong>稠密图</strong>表示。此处还是以 TSP 为例。</p>
<h4 id="tsp-py"><code>tsp.py</code></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">tsp_dense_process</span>(<span class="hljs-params">points: np.ndarray, ref_tour: np.ndarray</span>):<br>    <span class="hljs-comment"># check dimension</span><br>    check_dim(points, <span class="hljs-number">2</span>)<br>    check_dim(ref_tour, <span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># nodes_num</span><br>    nodes_num = points.shape[<span class="hljs-number">0</span>]<br>    <br>    <span class="hljs-comment"># x and graph</span><br>    x = to_tensor(points)<br>    graph = to_tensor(cdist(points, points)).<span class="hljs-built_in">float</span>()<br>    <br>    <span class="hljs-comment"># ground truth</span><br>    <span class="hljs-keyword">if</span> ref_tour <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        ground_truth = torch.zeros(size=(nodes_num, nodes_num))<br>        <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(ref_tour) - <span class="hljs-number">1</span>):<br>            ground_truth[ref_tour[idx]][ref_tour[idx+<span class="hljs-number">1</span>]] = <span class="hljs-number">1</span><br>        ground_truth = ground_truth + ground_truth.T<br>    <span class="hljs-keyword">else</span>:<br>        ground_truth = <span class="hljs-literal">None</span><br><br>    <span class="hljs-keyword">return</span> (<br>        x, <span class="hljs-comment"># (V, 2): nodes feature, random init</span><br>        graph.<span class="hljs-built_in">float</span>(), <span class="hljs-comment"># (V, V): edges feature, distance matrix</span><br>        ground_truth.long(), <span class="hljs-comment"># (V,): Ground truth</span><br>        nodes_num, <span class="hljs-comment"># Number of nodes</span><br>    )<br></code></pre></td></tr></table></figure>
<p><code>points</code> 的形状为 <code>(V, 2)</code>，是每个城市的二维坐标；<code>ref_tour</code> 的形状为 <code>(V+1,)</code>，表示参考路径。首先，检查输入维度，并提取节点数量。<code>x = to_tensor(points)</code> 直接使用节点的坐标作为其特征，转换为 Pytorch Tensor 格式。<code>graph = to_tensor(cdist(points, points)).float()</code> 计算距离矩阵并转换为 Tensor。接着，构建 <code>ground_truth</code>：遍历 <code>ref_tour</code> 序列，将其中的每一步在邻接矩阵中标记为 1，其余为 0，并通过 <code>ground_truth = ground_truth + ground_truth.T</code> 转换为无向图。最终，将所有处理好的数据打包成一个元组返回。</p>
<h3 id="sparser-py"><code>sparser.py</code></h3>
<p>与 <code>GNN4CODenser</code> 类似，<code>GNN4COSparser</code> 的作用时：接收一个批次 Numpy 格式的原始数据，并将它们转换成单个巨大的、由多个不相连子图组成的、PyTorch Tensor 格式的、适用于 GNN 模型的<strong>稀疏图</strong>表示。</p>
<p>稀疏图采用 <strong>COO (Coordinate Format)</strong>，用 <code>edge_index</code> 和 <code>edge_features</code> 表示图。<code>edge_index</code> 是一个形状为 <code>(2, E)</code> 的 Tensor，其中 <code>E</code> 是图中边的总数。第一行是所有边的源节点索引，第二行是对应的目标节点索引。<code>edge_features</code> 是一个形状为 <code>(E, D_e)</code> 的 Tensor，存储每条边的特征（如边的权重或距离）。对于节点很多但连接相对较少的图，稀疏表示法在内存占用和计算效率上远超稠密表示法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">GNN4COSparser</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, sparse_factor: <span class="hljs-built_in">int</span>, device: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-variable language_">self</span>.sparse_factor = sparse_factor<br>        <span class="hljs-variable language_">self</span>.device = device<br></code></pre></td></tr></table></figure>
<p>初始化部分，关注一下 <strong><code>sparse_factor</code> 参数</strong>，用来控制稀疏化的程度。通常代表 k-Nearest Neighbors (k-NN) 中的 k。即对于每个节点，只保留到它最近的 k 个邻居的边，从而将一个完全图稀疏化。但是注意，<strong>这只对选边问题有效</strong>。选点问题默认采用稀疏图，且 <code>sparse_factor</code> 不起作用，即我们不会丢弃任何边。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">initial_lists</span>(<span class="hljs-params">self</span>):<br>       <span class="hljs-variable language_">self</span>.x_list = <span class="hljs-built_in">list</span>()<br>       <span class="hljs-variable language_">self</span>.e_list = <span class="hljs-built_in">list</span>()<br>       <span class="hljs-variable language_">self</span>.edge_index_list = <span class="hljs-built_in">list</span>()<br>       <span class="hljs-variable language_">self</span>.graph_list = <span class="hljs-built_in">list</span>()<br>       <span class="hljs-variable language_">self</span>.ground_truth_list = <span class="hljs-built_in">list</span>()<br>       <span class="hljs-variable language_">self</span>.nodes_num_list = <span class="hljs-built_in">list</span>()<br>       <span class="hljs-variable language_">self</span>.edges_num_list = <span class="hljs-built_in">list</span>()<br>       <br>   <span class="hljs-keyword">def</span> <span class="hljs-title function_">update_lists</span>(<span class="hljs-params">self, sparse_data: <span class="hljs-type">Any</span></span>):<br>       <span class="hljs-variable language_">self</span>.x_list.append(sparse_data[<span class="hljs-number">0</span>])<br>       <span class="hljs-variable language_">self</span>.e_list.append(sparse_data[<span class="hljs-number">1</span>])<br>       <span class="hljs-variable language_">self</span>.edge_index_list.append(sparse_data[<span class="hljs-number">2</span>])<br>       <span class="hljs-variable language_">self</span>.graph_list.append(sparse_data[<span class="hljs-number">3</span>])<br>       <span class="hljs-variable language_">self</span>.ground_truth_list.append(sparse_data[<span class="hljs-number">4</span>])<br>       <span class="hljs-variable language_">self</span>.nodes_num_list.append(sparse_data[<span class="hljs-number">5</span>])<br>       <span class="hljs-variable language_">self</span>.edges_num_list.append(sparse_data[<span class="hljs-number">6</span>])<br></code></pre></td></tr></table></figure>
<p>与 <code>GNN4CODenser</code> 中的方法类似，此处略过。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">merge_process</span>(<span class="hljs-params">self, task: <span class="hljs-built_in">str</span>, with_gt: <span class="hljs-built_in">bool</span></span>) -&gt; <span class="hljs-type">Any</span>:<br>       <span class="hljs-comment"># nodes feature</span><br>       <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.x_list[<span class="hljs-number">0</span>] <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>           x = torch.cat(<span class="hljs-variable language_">self</span>.x_list, <span class="hljs-number">0</span>).to(<span class="hljs-variable language_">self</span>.device) <span class="hljs-comment"># (V, C) or (V,)</span><br>       <span class="hljs-keyword">else</span>:<br>           x = <span class="hljs-literal">None</span><br>           <br>       <span class="hljs-comment"># edges feature</span><br>       <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.e_list[<span class="hljs-number">0</span>] <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>           e = torch.cat(<span class="hljs-variable language_">self</span>.e_list, <span class="hljs-number">0</span>).to(<span class="hljs-variable language_">self</span>.device) <span class="hljs-comment"># (V, C) or (E,)</span><br>       <span class="hljs-keyword">else</span>:<br>           e = <span class="hljs-literal">None</span><br><br>       <span class="hljs-comment"># edge index</span><br>       add_index = <span class="hljs-number">0</span><br>       edge_index_list = <span class="hljs-built_in">list</span>()<br>       <span class="hljs-keyword">for</span> idx, edge_index <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(<span class="hljs-variable language_">self</span>.edge_index_list):<br>           edge_index_list.append(edge_index + add_index)<br>           add_index += <span class="hljs-variable language_">self</span>.nodes_num_list[idx]<br>       edge_index = torch.cat(edge_index_list, <span class="hljs-number">1</span>).to(<span class="hljs-variable language_">self</span>.device) <span class="hljs-comment"># (2, E)</span><br><br>       <span class="hljs-comment"># ground truth</span><br>       <span class="hljs-keyword">if</span> with_gt:<br>           ground_truth = torch.cat(<span class="hljs-variable language_">self</span>.ground_truth_list, <span class="hljs-number">0</span>).to(<span class="hljs-variable language_">self</span>.device) <span class="hljs-comment"># (E,) or (V,)</span><br>       <span class="hljs-keyword">else</span>:<br>           ground_truth = <span class="hljs-literal">None</span><br>           <br>       <span class="hljs-keyword">return</span> (<br>           task, x, e, edge_index, <span class="hljs-variable language_">self</span>.graph_list, <br>           ground_truth, <span class="hljs-variable language_">self</span>.nodes_num_list, <span class="hljs-variable language_">self</span>.edges_num_list<br>       )<br></code></pre></td></tr></table></figure>
<p><code>merge_process()</code> 方法用于<strong>实现稀疏图的批处理合并</strong>。注意，这里<strong>合并逻辑和稠密图不同</strong>。在主流 GNN 框架中，批处理稀疏图的标准做法不是将它们堆叠成一个 <code>(B, ...)</code> 的张量，而是将它们<strong>拼接成一个包含了所有子图的“巨图”（Giant Graph）</strong>。</p>
<p>首先，处理节点特征 <code>x</code> 和边特征 <code>e</code>。与之前使用的 <code>stack</code> 不同，这里是用的是 <code>cat</code>，即<strong>在原有维度上进行拼接</strong>。这两个函数的区别我们在 <a href="https://cny123222.github.io/2025/08/14/Fancy-but-Useful-Tensor-Operations/">Fancy but Useful Tensor Operations</a> 中介绍过。<code>cat()</code> 将所有图的所有节点特征和所有边特征分别拼接成一个长列表。</p>
<p>接着，处理边索引 <code>edge_index</code>。如果直接拼接 <code>edge_index</code>，所有图的节点索引都会从 0 开始，这会导致混淆。第二个图中的节点 0 会和第一个图中的节点 0 无法区分。因此，采用<strong>偏移索引</strong>的方法。例如，假设每个 TSP 实例都有 50 个节点，那么第一个图的节点编号为 0 到 49，第二个图的节点编号为 50 到 99，以此类推。对每个图的 <code>edge_index</code>，加上 <code>add_index</code> 这一偏移量，更新 <code>add_index</code>，最后在 <code>dim=1</code> 上拼接，形成形状为 <code>(2, total_E)</code> 的 Tensor。</p>
<p><code>ground_truth</code> 的处理逻辑与节点和边特征相同。最终，返回一个包含 8 个元素的元组，这是一个完整的、批处理过的稀疏图表示。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">tsp_batch_data_process</span>(<span class="hljs-params"></span><br><span class="hljs-params">       self, points: np.ndarray, ref_tours: np.ndarray, sampling_num: <span class="hljs-built_in">int</span> = <span class="hljs-number">1</span></span><br><span class="hljs-params">   </span>) -&gt; <span class="hljs-type">Any</span>:<br>       <span class="hljs-comment"># check dimension</span><br>       check_dim(points, <span class="hljs-number">3</span>)<br>       check_dim(ref_tours, <span class="hljs-number">2</span>)<br>       <br>       <span class="hljs-comment"># initialize lists</span><br>       <span class="hljs-variable language_">self</span>.initial_lists()<br>       <br>       <span class="hljs-comment"># sparse process</span><br>       <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(points.shape[<span class="hljs-number">0</span>]):<br>           sparse_data = tsp_sparse_process(<br>               points=points[idx], <br>               ref_tour=ref_tours[idx] <span class="hljs-keyword">if</span> ref_tours  <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>, <br>               sparse_factor=<span class="hljs-variable language_">self</span>.sparse_factor<br>           )<br>           <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(sampling_num):<br>               <span class="hljs-variable language_">self</span>.update_lists(sparse_data)<br>       <br>       <span class="hljs-comment"># merge</span><br>       <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.merge_process(<br>           task=<span class="hljs-string">&quot;TSP&quot;</span>, <br>           with_gt=<span class="hljs-literal">True</span> <span class="hljs-keyword">if</span> ref_tours <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">False</span><br>       )<br></code></pre></td></tr></table></figure>
<p>（此处省略 <code>atsp_batch_data_process</code> 等类似函数）</p>
<p><code>..._batch_data_process()</code> 是一系列类似的方法，是外部调用的接口。其内部逻辑与 <code>GNN4CODenser</code> 中的版本几乎完全相同，但<strong>支持选边和选点的所有问题</strong>。</p>
<h3 id="sparse"><code>sparse</code></h3>
<p>接着看稀疏图中<strong>单个实例的格式转换</strong>。这些函数位于 <code>sparse</code> 文件夹中，用于接收单个实例的 Numpy 格式的原始数据，通过 KNN 算法对其进行稀疏化，然后将其转换成 GNN 模型可以处理的稀疏图格式（节点特征、边特征、边索引和真值）。此处仍然以 TSP 为例。</p>
<h4 id="tsp-py-2"><code>tsp.py</code></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch.utils.data<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> Tensor<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Sequence</span><br><span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> KDTree<br><span class="hljs-keyword">from</span> ml4co_kit <span class="hljs-keyword">import</span> check_dim, to_tensor<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tsp_sparse_process</span>(<span class="hljs-params"></span><br><span class="hljs-params">    points: np.ndarray, ref_tour: np.ndarray, sparse_factor: <span class="hljs-built_in">int</span></span><br><span class="hljs-params"></span>) -&gt; <span class="hljs-type">Sequence</span>[Tensor]:<br>    <span class="hljs-comment"># check dimension</span><br>    check_dim(points, <span class="hljs-number">2</span>)<br>    check_dim(ref_tour, <span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># nodes_num and edges_num</span><br>    nodes_num = points.shape[<span class="hljs-number">0</span>]<br>    edges_num = nodes_num * sparse_factor<br>    <br>    <span class="hljs-comment"># KDTree        </span><br>    kdt = KDTree(points, leaf_size=<span class="hljs-number">30</span>, metric=<span class="hljs-string">&#x27;euclidean&#x27;</span>)<br>    dists_knn, idx_knn = kdt.query(points, k=sparse_factor, return_distance=<span class="hljs-literal">True</span>)<br>    e = to_tensor(dists_knn.reshape(-<span class="hljs-number">1</span>))<br>    <br>    <span class="hljs-comment"># edge_index</span><br>    edge_index_0 = torch.arange(nodes_num).reshape((-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    edge_index_0 = edge_index_0.repeat(<span class="hljs-number">1</span>, sparse_factor).reshape(-<span class="hljs-number">1</span>)<br>    edge_index_1 = torch.from_numpy(idx_knn.reshape(-<span class="hljs-number">1</span>))<br>    edge_index = torch.stack([edge_index_0, edge_index_1], dim=<span class="hljs-number">0</span>)<br>    <br>    <span class="hljs-comment"># ground truth</span><br>    <span class="hljs-keyword">if</span> ref_tour <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        tour_edges = np.zeros(nodes_num, dtype=np.int64)<br>        tour_edges[ref_tour[:-<span class="hljs-number">1</span>]] = ref_tour[<span class="hljs-number">1</span>:]<br>        tour_edges = torch.from_numpy(tour_edges)<br>        tour_edges = tour_edges.reshape((-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)).repeat(<span class="hljs-number">1</span>, sparse_factor).reshape(-<span class="hljs-number">1</span>)<br>        tour_edges = torch.eq(edge_index_1, tour_edges).reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>        <br>        tour_edges_rv = np.zeros(nodes_num, dtype=np.int64)<br>        tour_edges_rv[ref_tour[<span class="hljs-number">1</span>:]] = ref_tour[<span class="hljs-number">0</span>:-<span class="hljs-number">1</span>]<br>        tour_edges_rv = torch.from_numpy(tour_edges_rv)<br>        tour_edges_rv = tour_edges_rv.reshape((-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)).repeat(<span class="hljs-number">1</span>, sparse_factor).reshape(-<span class="hljs-number">1</span>)<br>        tour_edges_rv = torch.eq(edge_index_1, tour_edges_rv).reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>        ground_truth = (tour_edges + tour_edges_rv).reshape(-<span class="hljs-number">1</span>).long()<br>    <span class="hljs-keyword">else</span>:<br>        ground_truth = <span class="hljs-literal">None</span><br>    <br>    <span class="hljs-comment"># nodes feature</span><br>    x = to_tensor(points)<br>    <br>    <span class="hljs-keyword">return</span> (<br>        x.<span class="hljs-built_in">float</span>(), <span class="hljs-comment"># (V, 2): nodes feature, Euler coordinates of nodes</span><br>        e.<span class="hljs-built_in">float</span>(), <span class="hljs-comment"># (E,): edges feature, distance between nodes</span><br>        edge_index.long(), <span class="hljs-comment"># (2, E): Index of edge endpoints</span><br>        <span class="hljs-literal">None</span>, <span class="hljs-comment"># (V, V): Graph, but no need for TSP when sparse</span><br>        ground_truth, <span class="hljs-comment"># (V,): Ground truth</span><br>        nodes_num, <span class="hljs-comment"># Number of nodes</span><br>        edges_num <span class="hljs-comment"># Number of edges</span><br>    )<br></code></pre></td></tr></table></figure>
<p>首先，检查输入维度，并计算节点和边的数量。</p>
<p>接着，<strong>构建 KD 树</strong>，这是一种专门用于在高维空间中进行快速最近邻搜索的数据结构。对 <code>points</code> 数组中的每一个点，在 KD 树中查询离它最近的 <code>sparse_factor</code> 个点。返回的 <code>idx_knn</code> 形状为 <code>(V, sparse_factor)</code>，<code>idx_knn[i][j]</code> 是节点 <code>i</code> 的第 <code>j</code> 个最近邻的索引；<code>dists_knn</code> 形状也为 <code>(V, sparse_factor)</code>，<code>dists_knn[i][j]</code> 是节点 <code>i</code> 与其第 <code>j</code> 个最近邻之间的距离。<code>e = to_tensor(dists_knn.reshape(-1))</code> 将距离矩阵展平为一维数组，再转换为 Tensor，形状为 <code>(edges_num,)</code>。</p>
<p>然后，构建边索引 <code>edge_index</code>，形状为 <code>(2, E)</code>，对应 <code>e</code> 中每条边的源节点和目标节点。我们逐句分析一下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">edge_index_0 = torch.arange(nodes_num).reshape((-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure>
<p>创建了 <code>[0, 1, 2, ..., V-1]</code>，并将其形状变为 <code>(V, 1)</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">edge_index_0 = edge_index_0.repeat(<span class="hljs-number">1</span>, sparse_factor).reshape(-<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>
<p>每行重复 <code>sparse_factor</code> 次，将其变成 <code>[[0, 0, ...], [1, 1, ...], ...]</code> 的形式，再展平成 <code>[0, 0, ..., 1, 1, ..., V-1, V-1, ...]</code>。这完美地构造了所有边的<strong>源节点列表</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">edge_index_1 = torch.from_numpy(idx_knn.reshape(-<span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure>
<p>直接将 <code>idx_knn</code> (最近邻索引矩阵) 展平并转换为 Tensor。这自然地构成了所有边的<strong>目标节点列表</strong>。</p>
<p>最终，将源节点列表和目标节点列表堆叠起来，形成 <code>(2, E)</code> 的 <code>edge_index</code>。</p>
<p>接着，构建真值 <code>ground_truth</code>，为稀疏图中的每一条边打上标签（1 代表属于最优路径，0 代表不属于）。首先构建正向路径 <code>tour_edges</code>，还是一句句看。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">tour_edges[ref_tour[:-<span class="hljs-number">1</span>]] = ref_tour[<span class="hljs-number">1</span>:]<br></code></pre></td></tr></table></figure>
<p>这句使用高级索引，创建了一个映射。如果 <code>ref_tour</code> 是 <code>[0, 2, 1, 3, 0]</code>，那么 <code>tour_edges</code> 就会变成 <code>[2, 3, 1, 0]</code>。<code>tour_edges[i]</code> 表示在最优路径中，节点 <code>i</code> 的下一个节点的序号。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">tour_edges = tour_edges.reshape((-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)).repeat(<span class="hljs-number">1</span>, sparse_factor).reshape(-<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>
<p>与之前 <code>edge_index</code> 中操作类似，这步将这个映射扩展成形状 <code>(E,)</code>。现在，对于源节点 <code>i</code> 的所有 <code>sparse_factor</code> 条出边，它们对应的 <code>tour_edges</code> 值都是 <code>i</code> 在最优路径中的下一个节点。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">tour_edges = torch.eq(edge_index_1, tour_edges).reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>
<p>逐元素地比较 <code>edge_index_1</code> (真实的目标节点) 和 <code>tour_edges</code> (期望的目标节点)。只有当一条边的真实目标节点恰好是源节点在最优路径中的下一个节点时，结果才为 <code>True</code>。</p>
<p>接着，构建反向路径 <code>tour_edges_rv</code>，即反过来走 <code>ref_tour</code> 中的路线。这是为了将 TSP 的无向路径考虑进来。最终，将正向和反向的结果相加。一条边只要在正向或反向路径中出现，它的标签就会是 1。得到的 <code>ground_truth</code> 是一个形状为 <code>(E,)</code> 的一维 Tensor，对应了稀疏图中的每一条边。</p>
<p>最后，使用坐标作为节点特征，并打包返回。注意，TSP 不再需要图信息，故元组的第 4 个元素为 <code>None</code>。</p>
<h2 id="Solver">Solver</h2>
<p><code>Solver</code> 中封装了各个问题的求解器，供测试阶段调用。此处我们以 TSP 的 solver 为例。</p>
<p>测试脚本如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    solver = GNN4COTSPSolver(<br>        model=GNN4COModel(<br>            env=GNN4COEnv(<br>                task=<span class="hljs-string">&quot;TSP&quot;</span>, sparse_factor=SPARSE_FACTOR, device=<span class="hljs-string">&quot;cuda&quot;</span><br>            ),<br>            encoder=TSPGNNEncoder(sparse=SPARSE_FACTOR&gt;<span class="hljs-number">0</span>),<br>            decoder=TSPDecoder(<br>                decoding_type=SOLVING_SETTINGS[<span class="hljs-number">0</span>], <br>                local_search_type=SOLVING_SETTINGS[<span class="hljs-number">1</span>],<br>                mcts_time_limit=MCTS_TIME_LIMIT,<br>                mcts_type_2opt=MCTS_TYPE_FLAG<br>            ),<br>            weight_path=WEIGHT_PATH_DICT[NODES_NUM]<br>        )<br>    )<br>    solver.from_txt(TEST_FILE_DICT[NODES_NUM], ref=<span class="hljs-literal">True</span>, show_time=<span class="hljs-literal">True</span>)<br>    solver.solve(show_time=<span class="hljs-literal">True</span>)<br>    <span class="hljs-built_in">print</span>(solver.evaluate(calculate_gap=<span class="hljs-literal">True</span>))<br></code></pre></td></tr></table></figure>
<h3 id="tsp-py-3"><code>tsp.py</code></h3>
<p>这个 <code>GNN4COTSPSolver</code> 继承自 <code>ml4co_kit</code> 中的 <code>TSPSolver</code>，重载了其中的 <code>solve()</code> 方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">GNN4COTSPSolver</span>(<span class="hljs-title class_ inherited__">TSPSolver</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, model: GNN4COModel, seed: <span class="hljs-built_in">int</span> = <span class="hljs-number">1234</span></span>):<br>        <span class="hljs-built_in">super</span>(GNN4COTSPSolver, <span class="hljs-variable language_">self</span>).__init__(solver_type=SOLVER_TYPE.ML4TSP)<br>        <span class="hljs-variable language_">self</span>.model: GNN4COModel = model<br>        <span class="hljs-variable language_">self</span>.model.<span class="hljs-built_in">eval</span>()<br>        <span class="hljs-variable language_">self</span>.model.env.mode = <span class="hljs-string">&quot;solve&quot;</span><br>        torch.manual_seed(seed=seed)<br></code></pre></td></tr></table></figure>
<p>初始化阶段，注意 <code>torch.manual_seed(seed=seed)</code> 这一步，是在设置随机种子，<strong>以保证任何可能存在的随机性（如解码阶段的采样）都是可复现的</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">solve</span>(<span class="hljs-params"></span><br><span class="hljs-params">    self, batch_size: <span class="hljs-built_in">int</span> = <span class="hljs-number">1</span>, sampling_num: <span class="hljs-built_in">int</span> = <span class="hljs-number">1</span>, show_time: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span></span><br><span class="hljs-params"></span>):<br>    <span class="hljs-comment"># timer</span><br>    timer = Timer(apply=show_time)<br>    timer.start()<br>    <br>    <span class="hljs-comment"># solve</span><br>    msg = <span class="hljs-string">f&quot;Solving solutions using GNN4COTSPSolver&quot;</span><br>    samples_num = <span class="hljs-built_in">len</span>(<span class="hljs-variable language_">self</span>.points)<br>    solutions_list = <span class="hljs-built_in">list</span>()<br>    <span class="hljs-variable language_">self</span>._normalize_points()<br>    <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> iterative_execution(<span class="hljs-built_in">range</span>, samples_num // batch_size, msg, show_time):<br>        <span class="hljs-comment"># begin index and end index</span><br>        begin_idx = idx * batch_size<br>        end_idx = begin_idx + batch_size<br>        <br>        <span class="hljs-comment"># data processor</span><br>        data = <span class="hljs-variable language_">self</span>.model.env.data_processor.tsp_batch_data_process(<br>            points=<span class="hljs-variable language_">self</span>.points[begin_idx:end_idx], <br>            ref_tours=<span class="hljs-variable language_">self</span>.ref_tours[begin_idx:end_idx], <br>            sampling_num=sampling_num<br>        )<br><br>        <span class="hljs-comment"># inference to get heatmap and decoding</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.model.env.sparse:<br>            <span class="hljs-keyword">with</span> torch.no_grad():<br>                heatmap = <span class="hljs-variable language_">self</span>.model.inference_edge_sparse_process(*data)<br>                solutions = <span class="hljs-variable language_">self</span>.model.decoder.sparse_decode(heatmap, *data)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">with</span> torch.no_grad():<br>                heatmap = <span class="hljs-variable language_">self</span>.model.inference_edge_dense_process(*data)<br>                solutions = <span class="hljs-variable language_">self</span>.model.decoder.dense_decode(heatmap, *data)<br>                <br>        <span class="hljs-comment"># solution list</span><br>        solutions_list += solutions<br><br>    <span class="hljs-comment"># timer</span><br>    timer.end()<br>    timer.show_time()<br>    <br>    <span class="hljs-comment"># restore solution</span><br>    <span class="hljs-variable language_">self</span>.from_data(tours=solutions_list, ref=<span class="hljs-literal">False</span>)<br>    <br>    <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.tours<br></code></pre></td></tr></table></figure>
<p>这一方法的作用是：接收待求解的 TSP 实例（存储在 <code>self.points</code> 中），分批次进行处理，并返回最终的解。</p>
<p>首先，启动计时器，用于计算求解时间，并获取待求解实例的总数 <code>samples_num</code>，并归一化所有坐标。</p>
<p>接着，进入 <code>for</code> 循环，将总样本按 <code>batch_size</code> 分块处理。</p>
<ul>
<li><strong>数据准备</strong>：求解器从自己的 <code>self.points</code> 中切出一个批次的数据，并调用数据处理器 <code>self.model.env.data_processor</code> 来完成所有的预处理工作。- <strong>模型推理与解码</strong>：根据稀疏图和稠密图的不同，调用模型的核心推理方法 <code>inference_edge_sparse_process()</code> 或 <code>inference_edge_dense_process()</code>，得到 <code>heatmap</code>，这是一个代表每条边属于最优路径的概率的张量。接着，解码器 <code>self.model.decoder</code> 接收 GNN 生成的 <code>heatmap</code>，根据这些概率构造出一条具体的、合法的路径 <code>solutions</code>。</li>
</ul>
<p>最后，计时器停止计时并显示耗时，求解得到的路径列表 <code>solutions_list</code> 被存入 <code>self.tours</code> 中，返回最终的解。</p>
<h2 id="Model">Model</h2>
<p>接下来，我们进入核心的 GNN 模型。模型主要包含 <code>Env</code>、<code>Encoder</code> 和 <code>Decoder</code> 三部分。</p>
<p>在看模型之前，我们先看一下 GNN4CO 的训练脚本：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    model=GNN4COModel(<br>        env=GNN4COEnv(<br>            task=<span class="hljs-string">&quot;TSP&quot;</span>, <br>            mode=<span class="hljs-string">&quot;train&quot;</span>, <br>            train_data_size=<span class="hljs-number">128000</span>,<br>            val_data_size=<span class="hljs-number">1280</span>,<br>            train_batch_size=<span class="hljs-number">64</span>,<br>            val_batch_size=<span class="hljs-number">1</span>,<br>            sparse_factor=-<span class="hljs-number">1</span>, <br>            device=<span class="hljs-string">&quot;cuda&quot;</span>,<br>            train_folder=<span class="hljs-string">&quot;path/to/train/folder&quot;</span>,<br>            val_path=<span class="hljs-string">&quot;path/to/val/file&quot;</span>,<br>            store_data=<span class="hljs-literal">True</span> <span class="hljs-comment"># set False if your server&#x27;s memory is not large enough.</span><br>        ),<br>        encoder=TSPGNNEncoder(sparse=<span class="hljs-literal">False</span>),<br>        decoder=TSPDecoder(),<br>        <span class="hljs-comment"># weight_path=&quot;path/to/pretrained/file&quot;</span><br>    )<br><br>    trainer = Trainer(model=model, devices=[<span class="hljs-number">0</span>], max_epochs=<span class="hljs-number">50</span>)<br>    trainer.model_train()<br></code></pre></td></tr></table></figure>
<p>使用的是 <strong><code>ml4co_kit</code> 封装的 Pytorch Lightning 框架</strong>进行训练。</p>
<h3 id="model-py"><code>model.py</code></h3>
<p>我们首先来看核心的 <code>GNN4COModel</code> 类。这是一个完整的、端到端的机器学习模型，该模型能够根据不同的任务和数据格式（稀疏或稠密），执行训练、验证和推理，并计算损失、生成 heatmap，以及记录评估指标。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">GNN4COModel</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        env: GNN4COEnv,</span><br><span class="hljs-params">        encoder: GNNEncoder,</span><br><span class="hljs-params">        decoder: GNN4CODecoder,</span><br><span class="hljs-params">        lr_scheduler: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;cosine-decay&quot;</span>,</span><br><span class="hljs-params">        learning_rate: <span class="hljs-built_in">float</span> = <span class="hljs-number">2e-4</span>,</span><br><span class="hljs-params">        weight_decay: <span class="hljs-built_in">float</span> = <span class="hljs-number">1e-4</span>,</span><br><span class="hljs-params">        weight_path: <span class="hljs-built_in">str</span> = <span class="hljs-literal">None</span></span><br><span class="hljs-params">    </span>):<br>        <span class="hljs-built_in">super</span>(GNN4COModel, <span class="hljs-variable language_">self</span>).__init__(<br>            env=env,<br>            model=encoder,<br>            lr_scheduler=lr_scheduler,<br>            learning_rate=learning_rate,<br>            weight_decay=weight_decay<br>        )<br>        <span class="hljs-variable language_">self</span>.env: GNN4COEnv<br>        <span class="hljs-variable language_">self</span>.model: GNNEncoder<br>        <span class="hljs-variable language_">self</span>.decoder: GNN4CODecoder = decoder<br>        <br>        <span class="hljs-comment"># load pretrained weights if needed</span><br>        <span class="hljs-keyword">if</span> weight_path <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            state_dict = torch.load(weight_path, map_location=<span class="hljs-string">&quot;cpu&quot;</span>)<br>            <span class="hljs-variable language_">self</span>.load_state_dict(state_dict, strict=<span class="hljs-literal">True</span>)<br>        <span class="hljs-variable language_">self</span>.to(<span class="hljs-variable language_">self</span>.env.device)<br></code></pre></td></tr></table></figure>
<p>初始化函数，保存了 <code>env</code>、<code>encoder</code> 和 <code>decoder</code> 等。如果提供了 <code>weight_path</code>，会从该路径加载模型的状态字典 <code>state_dict</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">shared_step</span>(<span class="hljs-params">self, batch: <span class="hljs-type">Any</span>, batch_idx: <span class="hljs-built_in">int</span>, phase: <span class="hljs-built_in">str</span></span>):<br>       <span class="hljs-comment"># set mode</span><br>       <span class="hljs-variable language_">self</span>.env.mode = phase<br>       <br>       <span class="hljs-comment"># get real data</span><br>       <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">       task: ATSP or CVRP or MCl or MCut or MIS or MVC or TSP</span><br><span class="hljs-string">       if sparse:</span><br><span class="hljs-string">           [0] task</span><br><span class="hljs-string">           [1] x: (V, C) or (V,) , nodes feature</span><br><span class="hljs-string">           [2] e: (E, D) or (E,) , edges feature</span><br><span class="hljs-string">           [3] edge_index: (2, E)</span><br><span class="hljs-string">           [4] graph_list: graph data</span><br><span class="hljs-string">           [5] ground_truth: (E,) or (V,)</span><br><span class="hljs-string">           [6] nodes_num_list</span><br><span class="hljs-string">           [7] edges_num_list</span><br><span class="hljs-string">       else:</span><br><span class="hljs-string">           [0] task</span><br><span class="hljs-string">           [1] x: (B, V, C) or (B, V), nodes_feature</span><br><span class="hljs-string">           [2] graph: (B, V, V)</span><br><span class="hljs-string">           [3] ground_truth: (B, V, V) or (B, V)</span><br><span class="hljs-string">           [4] nodes_num_list</span><br><span class="hljs-string">       &quot;&quot;&quot;</span><br>       <span class="hljs-keyword">if</span> phase == <span class="hljs-string">&quot;train&quot;</span>:<br>           <span class="hljs-comment"># get real train batch data</span><br>           batch_size = <span class="hljs-built_in">len</span>(batch)<br>           batch_data = <span class="hljs-variable language_">self</span>.env.generate_train_data(batch_size)<br>           task = batch_data[<span class="hljs-number">0</span>]<br>           <br>           <span class="hljs-comment"># deal with different task</span><br>           <span class="hljs-keyword">if</span> task <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;TSP&quot;</span>, <span class="hljs-string">&quot;ATSP&quot;</span>, <span class="hljs-string">&quot;CVRP&quot;</span>]:<br>               <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.env.sparse:<br>                   loss = <span class="hljs-variable language_">self</span>.train_edge_sparse_process(*batch_data)<br>               <span class="hljs-keyword">else</span>:<br>                   loss = <span class="hljs-variable language_">self</span>.train_edge_dense_process(*batch_data)<br>           <span class="hljs-keyword">elif</span> task <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;MIS&quot;</span>, <span class="hljs-string">&quot;MCut&quot;</span>, <span class="hljs-string">&quot;MCl&quot;</span>, <span class="hljs-string">&quot;MVC&quot;</span>]:<br>               <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.env.sparse:<br>                   loss = <span class="hljs-variable language_">self</span>.train_node_sparse_process(*batch_data)<br>               <span class="hljs-keyword">else</span>:<br>                   loss = <span class="hljs-variable language_">self</span>.train_node_dense_process(*batch_data)<br>           <span class="hljs-keyword">else</span>:<br>               <span class="hljs-keyword">raise</span> NotImplementedError()<br>           <br>       <span class="hljs-keyword">elif</span> phase == <span class="hljs-string">&quot;val&quot;</span>:<br>           <span class="hljs-comment"># get val data</span><br>           batch_data = <span class="hljs-variable language_">self</span>.env.generate_val_data(batch_idx)<br>           task = batch_data[<span class="hljs-number">0</span>]<br>           <br>           <span class="hljs-comment"># deal with different task</span><br>           <span class="hljs-keyword">if</span> task <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;TSP&quot;</span>, <span class="hljs-string">&quot;ATSP&quot;</span>, <span class="hljs-string">&quot;CVRP&quot;</span>]:<br>               <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.env.sparse:<br>                   loss, heatmap = <span class="hljs-variable language_">self</span>.inference_edge_sparse_process(*batch_data)<br>               <span class="hljs-keyword">else</span>:<br>                   loss, heatmap = <span class="hljs-variable language_">self</span>.inference_edge_dense_process(*batch_data)<br>                   <br>           <span class="hljs-keyword">elif</span> task <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;MIS&quot;</span>, <span class="hljs-string">&quot;MCut&quot;</span>, <span class="hljs-string">&quot;MCl&quot;</span>, <span class="hljs-string">&quot;MVC&quot;</span>]:<br>               <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.env.sparse:<br>                   loss, heatmap = <span class="hljs-variable language_">self</span>.inference_node_sparse_process(*batch_data)<br>               <span class="hljs-keyword">else</span>:<br>                   loss, heatmap = <span class="hljs-variable language_">self</span>.inference_node_dense_process(*batch_data)<br>           <span class="hljs-keyword">else</span>:<br>               <span class="hljs-keyword">raise</span> NotImplementedError()<br>           <br>           <span class="hljs-comment"># decoding</span><br>           <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.env.sparse:<br>               costs_avg = <span class="hljs-variable language_">self</span>.decoder.sparse_decode(heatmap, *batch_data, return_cost=<span class="hljs-literal">True</span>)<br>           <span class="hljs-keyword">else</span>:<br>               costs_avg = <span class="hljs-variable language_">self</span>.decoder.dense_decode(heatmap, *batch_data, return_cost=<span class="hljs-literal">True</span>)<br>       <span class="hljs-keyword">else</span>:<br>           <span class="hljs-keyword">raise</span> NotImplementedError()<br>    <br>       <span class="hljs-comment"># log</span><br>       metrics = &#123;<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;phase&#125;</span>/loss&quot;</span>: loss&#125;<br>       <span class="hljs-keyword">if</span> phase == <span class="hljs-string">&quot;val&quot;</span>:<br>           metrics.update(&#123;<span class="hljs-string">&quot;val/costs_avg&quot;</span>: costs_avg&#125;)<br>       <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> metrics.items():<br>           formatted_v = <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;v:<span class="hljs-number">.8</span>f&#125;</span>&quot;</span><br>           <span class="hljs-variable language_">self</span>.log(k, <span class="hljs-built_in">float</span>(formatted_v), prog_bar=<span class="hljs-literal">True</span>, on_epoch=<span class="hljs-literal">True</span>, sync_dist=<span class="hljs-literal">True</span>)<br>       <br>       <span class="hljs-comment"># return</span><br>       <span class="hljs-keyword">return</span> loss <span class="hljs-keyword">if</span> phase == <span class="hljs-string">&quot;train&quot;</span> <span class="hljs-keyword">else</span> metrics <br></code></pre></td></tr></table></figure>
<p><code>shared_step()</code> 方法是 <code>ml4co_kit</code> 封装的<strong>训练/验证/测试步骤的统一入口</strong>，这里负责<strong>调度数据生成、模型前向传播、损失计算和指标记录</strong>。它根据 phase（“train” 或 “val”）来执行不同的逻辑，分别重载了 Pytorch Lightning 的 <code>training_step()</code> 和 <code>validation_step()</code> 方法。它接收一个批次的数据，返回训练损失或验证指标结果。</p>
<p>需要注意，这里的 <code>batch</code> 是 <code>Dataloader</code> 从 <code>FakeDataset</code> 加载的伪数据，并不是真实数据。真实的训练和验证数据在这个函数中进行生成。<code>batch_idx</code> 是当前批次的索引，用于验证是从 <code>val_dataset</code> 中定位数据。</p>
<p>首先，通知数据环境当前所处的阶段。接着，获取真实数据：</p>
<ul>
<li>如果处于训练阶段：调用 <code>self.env.generate_train_data()</code> 动态生成一批训练数据。</li>
<li>如果处于验证阶段：调用 <code>self.env.generate_val_data(batch_idx)</code> 生成当前索引对应的验证数据。</li>
</ul>
<p>然后，根据任务类型的不同（选边 / 选点）以及图表示方式的不同（稠密图 / 稀疏图），调用对应的 <code>train_..._process()</code> 或 <code>inference_..._process()</code> 方法来执行模型的前向传播，获得最终损失；如果处于验证阶段，还会返回 <code>heatmap</code>，并调用 <code>self.decoder</code> 的 <code>sparse_decode()</code> 或 <code>dense_decode()</code> 方法，获得平均成本 <code>costs_avg</code>。</p>
<p>最后，记录和返回结果。如果处于训练阶段，返回 <code>loss</code> 张量，框架会自动进行反向传播和参数更新；如果处于验证阶段，记录并返回一个包含 <code>loss</code> 和 <code>costs_avg</code> 的指标字典。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_edge_sparse_process</span>(<span class="hljs-params"></span><br><span class="hljs-params">       self, task: <span class="hljs-built_in">str</span>, x: Tensor, e: Tensor, edge_index: Tensor, graph_list: <span class="hljs-type">List</span>[Tensor], </span><br><span class="hljs-params">       ground_truth: Tensor, nodes_num_list: <span class="hljs-built_in">list</span>, edges_num_list: <span class="hljs-built_in">list</span></span><br><span class="hljs-params">   </span>) -&gt; Tensor:<br>       x_pred, e_pred = <span class="hljs-variable language_">self</span>.model.forward(<br>           task=task, x=x, e=e, edge_index=edge_index<br>       )<br>       <span class="hljs-keyword">del</span> x_pred<br>       loss = nn.CrossEntropyLoss()(e_pred, ground_truth)<br>       <span class="hljs-keyword">return</span> loss<br></code></pre></td></tr></table></figure>
<p>（此处省略类似的 <code>train_edge_dense_process</code>、<code>train_node_sparse_process</code> 和 <code>train_node_dense_process</code> 函数）</p>
<p>这是一组<strong>训练函数</strong>，它们接收一批处理好的数据，通过模型进行前向传播，并计算出用于反向传播的损失值。此处以 <code>train_edge_sparse_process</code> 为例。</p>
<p>函数接收一批稀疏图数据，调用 GNN 编码器 <code>self.model</code> 进行前向传播。输入是节点特征 <code>x</code>、边特征 <code>e</code> 和图结构 <code>edge_index</code>。输出是更新后的节点预测 <code>x_pred</code> 和边预测 <code>e_pred</code>。由于这是边预测任务，我们只关心 <code>e_pred</code>，可以删除 <code>x_pred</code> 以释放 GPU 内存。</p>
<p>然后计算损失，使用交叉熵损失函数 <code>nn.CrossEntropyLoss()</code>。<code>e_pred</code> 是未经 Softmax 的原始分数（logits），形状为 <code>(E, 2)</code>。<code>ground_truth</code> 是一个包含 0 或 1 的 Tensor，形状为 <code>(E,)</code>。交叉熵是这种多分类任务的标准损失函数。最终，返回计算出的损失。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">inference_edge_sparse_process</span>(<span class="hljs-params"></span><br><span class="hljs-params">       self, task: <span class="hljs-built_in">str</span>, x: Tensor, e: Tensor, edge_index: Tensor, graph_list: <span class="hljs-type">List</span>[Tensor], </span><br><span class="hljs-params">       ground_truth: Tensor, nodes_num_list: <span class="hljs-built_in">list</span>, edges_num_list: <span class="hljs-built_in">list</span></span><br><span class="hljs-params">   </span>) -&gt; <span class="hljs-type">Union</span>[Tensor, <span class="hljs-type">Tuple</span>[Tensor, Tensor]]:<br>       <span class="hljs-comment"># inference</span><br>       x_pred, e_pred = <span class="hljs-variable language_">self</span>.model.forward(<br>           task=task, x=x, e=e, edge_index=edge_index<br>       )<br>       <span class="hljs-keyword">del</span> x_pred<br>       <br>       <span class="hljs-comment"># heatmap</span><br>       e_pred_softmax = e_pred.softmax(dim=-<span class="hljs-number">1</span>)<br>       e_heatmap = e_pred_softmax[:, <span class="hljs-number">1</span>]<br>       <br>       <span class="hljs-comment"># return</span><br>       <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.env.mode == <span class="hljs-string">&quot;val&quot;</span>:<br>           loss = nn.CrossEntropyLoss()(e_pred, ground_truth)<br>           <span class="hljs-keyword">return</span> loss, e_heatmap<br>       <span class="hljs-keyword">elif</span> <span class="hljs-variable language_">self</span>.env.mode == <span class="hljs-string">&quot;solve&quot;</span>:<br>           <span class="hljs-keyword">return</span> e_heatmap<br>       <span class="hljs-keyword">else</span>:<br>           <span class="hljs-keyword">raise</span> ValueError()<br></code></pre></td></tr></table></figure>
<p>（此处省略类似的 <code>inference_edge_dense_process</code>、<code>inference_node_sparse_process</code> 和 <code>inference_node_dense_process</code> 函数）</p>
<p>这是一组<strong>推理函数</strong>。它们进行模型的前向传播，并生成一个 heatmap，表示每个元素（边或节点）属于解的概率。在验证模式下，还会计算并返回损失。</p>
<p>首先，与训练时一样，进行前向传播，获得 <code>x_pred</code> 和 <code>e_pred</code>。接着，将模型输出的 logits 通过 Softmax 转换成概率分布。对于每条边，我们现在得到 [P(不属于解), P(属于解)]。由于我们只关心属于解的概率，所以从最后一维中取出索引为 1 的概率值。这个结果	<code>e_heatmap</code> 就是一个形状为 <code>(E,)</code> 的 Tensor，可以直接被解码器使用。如果处于验证模式，计算损失，返回损失及 heatmap；如果处于求解模式，只返回 heatmap。</p>
<h3 id="embedder"><code>embedder</code></h3>
<p><code>embedder</code> 文件夹中包含了多种问题的 Embedder。它们是 Encoder 的第一层，用于将原始的输入数据转换成一个高维的、信息丰富的向量表示（即 Embedding），以便于后续 GNN 层能够理解和处理。</p>
<h4 id="base-py"><code>base.py</code></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">GNN4COEmbedder</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, hidden_dim: <span class="hljs-built_in">int</span>, sparse: <span class="hljs-built_in">bool</span></span>):<br>        <span class="hljs-built_in">super</span>(GNN4COEmbedder, <span class="hljs-variable language_">self</span>).__init__()<br>        <br>        <span class="hljs-comment"># dims</span><br>        <span class="hljs-variable language_">self</span>.hidden_dim = hidden_dim<br><br>        <span class="hljs-comment"># sparse</span><br>        <span class="hljs-variable language_">self</span>.sparse = sparse<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x: Tensor, e: Tensor</span>) -&gt; <span class="hljs-type">Sequence</span>[Tensor]:<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            [sparse]</span><br><span class="hljs-string">                x: (V,) or (V, C)</span><br><span class="hljs-string">                e: (E,) or (E, C) </span><br><span class="hljs-string">            [dense]</span><br><span class="hljs-string">                x: (B, V) or (B, V, C)</span><br><span class="hljs-string">                e: (B, V, V) </span><br><span class="hljs-string">        Return:</span><br><span class="hljs-string">            [sparse]</span><br><span class="hljs-string">                x: (V, H)</span><br><span class="hljs-string">                e: (E, H)</span><br><span class="hljs-string">            [dense]</span><br><span class="hljs-string">                x: (B, V, H) </span><br><span class="hljs-string">                e: (B, V, V, H) </span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.sparse:<br>            <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.sparse_forward(x, e)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.dense_forward(x, e)<br></code></pre></td></tr></table></figure>
<p><code>GNN4COEmbedder</code> 是一个基类，只实现了基本的初始化和根据 <code>self.sparse</code> 进行分发的 <code>forward()</code> 方法。</p>
<h4 id="tsp-py-4"><code>tsp.py</code></h4>
<p>这里以 TSP 问题具体举例。<code>TSPEmbedder</code> 接收TSP问题的原始输入（节点的二维坐标 <code>x</code> 和边的距离 <code>e</code>），并将这些低维的标量或向量，通过神经网络，映射成高维的、GNN 友好的<strong>节点嵌入和边嵌入</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">TSPEmbedder</span>(<span class="hljs-title class_ inherited__">GNN4COEmbedder</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, hidden_dim: <span class="hljs-built_in">int</span>, sparse: <span class="hljs-built_in">bool</span></span>):<br>        <span class="hljs-built_in">super</span>(TSPEmbedder, <span class="hljs-variable language_">self</span>).__init__(hidden_dim, sparse)<br>        <br>        <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.sparse:<br>            <span class="hljs-comment"># node embedder</span><br>            <span class="hljs-variable language_">self</span>.node_embed = nn.Sequential(<br>                PositionEmbeddingSine(hidden_dim // <span class="hljs-number">2</span>),<br>                nn.Linear(hidden_dim, hidden_dim)<br>            )<br>        <br>            <span class="hljs-comment"># edge embedder</span><br>            <span class="hljs-variable language_">self</span>.edge_embed = nn.Sequential(<br>                ScalarEmbeddingSine1D(hidden_dim),<br>                nn.Linear(hidden_dim, hidden_dim)<br>            )<br>            <br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># node embedder</span><br>            <span class="hljs-variable language_">self</span>.node_embed = nn.Sequential(<br>                PositionEmbeddingSine(hidden_dim // <span class="hljs-number">2</span>),<br>                nn.Linear(hidden_dim, hidden_dim)<br>            )<br>        <br>            <span class="hljs-comment"># edge embedder</span><br>            <span class="hljs-variable language_">self</span>.edge_embed = nn.Sequential(<br>                ScalarEmbeddingSine3D(hidden_dim),<br>                nn.Linear(hidden_dim, hidden_dim)<br>            )<br></code></pre></td></tr></table></figure>
<p>这边主要是 Embedder 网络的构造。注意 <strong><code>hidden_dim</code> 是整个 GNN 模型的隐藏维度</strong>，即所有嵌入的维度都将是 <code>hidden_dim</code>。</p>
<p>首先，对于节点嵌入，使用 <code>PositionEmbeddingSine(hidden_dim // 2)</code>，这是<strong>正弦位置编码</strong>（Sinusoidal Positional Encoding）。它能将一个连续的坐标值 <code>(x, y)</code> 映射到一个高维向量中，这个向量同时编码了该位置的绝对信息和相对信息。<code>hidden_dim // 2</code> 是因为每个维度（x 和 y）都会被编码成 <code>hidden_dim // 2</code> 维的向量，然后拼接起来。对于稀疏表示，输入是形状为 <code>(V, 2)</code> 的节点坐标，输出是形状为 <code>(V, H)</code> 的节点嵌入；对于稠密表示，输入是形状为 <code>(B, V, 2)</code> 的节点坐标，输出是形状为 <code>(B, V, H)</code> 的节点嵌入。（这是因为稀疏图中，一个批次的数据已经拼成了一张巨图。）然后是一个标准的全连接层 <code>nn.Linear(hidden_dim, hidden_dim)</code>。</p>
<p>其次，对于边嵌入，</p>
<ul>
<li>如果是<strong>稀疏表示</strong>：使用 <code>ScalarEmbeddingSine1D(hidden_dim)</code>。这是一个<strong>为一维标量（如距离）设计的正弦编码</strong>，能将一个标量映射成一个<code>hidden_dim</code> 维的高维向量。输入是形状为 <code>(E, )</code> 的边距离，输出是形状为 <code>(E, H)</code> 的边嵌入。然后是一个标准的全连接层。</li>
<li>如果是<strong>稠密表示</strong>：使用 <code>ScalarEmbeddingSine3D(hidden_dim)</code>。这是一个<strong>为三维 Tensor 设计的正弦编码</strong>。输入是形状为 <code>(B, V, V)</code> 的距离矩阵，输出是形状为 <code>(B, V, V, H)</code> 的高维表示。然后同样是一个标准的全连接层。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sparse_forward</span>(<span class="hljs-params">self, x: Tensor, e: Tensor</span>) -&gt; <span class="hljs-type">Sequence</span>[Tensor]:<br>       <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">       Args:</span><br><span class="hljs-string">           x: (V, 2) nodes_feature (node coords)</span><br><span class="hljs-string">           e: (E,) edges_feature (distance matrix)</span><br><span class="hljs-string">       Return:</span><br><span class="hljs-string">           x: (V, H)</span><br><span class="hljs-string">           e: (E, H)</span><br><span class="hljs-string">       &quot;&quot;&quot;</span>   <br>       x = <span class="hljs-variable language_">self</span>.node_embed(x) <span class="hljs-comment"># (V, H)</span><br>       e = <span class="hljs-variable language_">self</span>.edge_embed(e) <span class="hljs-comment"># (E, H)</span><br>       <span class="hljs-keyword">return</span> x, e<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">dense_forward</span>(<span class="hljs-params">self, x: Tensor, e: Tensor</span>) -&gt; <span class="hljs-type">Sequence</span>[Tensor]:<br>       <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">       Args:</span><br><span class="hljs-string">           x: (B, V, 2) nodes_feature (node coords)</span><br><span class="hljs-string">           e: (B, V, V) edges_feature (distance matrix)</span><br><span class="hljs-string">       Return:</span><br><span class="hljs-string">           x: (B, V, H)</span><br><span class="hljs-string">           e: (B, V, V, H)</span><br><span class="hljs-string">       &quot;&quot;&quot;</span><br>       x = <span class="hljs-variable language_">self</span>.node_embed(x) <span class="hljs-comment"># (B, V, H)</span><br>       e = <span class="hljs-variable language_">self</span>.edge_embed(e) <span class="hljs-comment"># (B, V, V, H)</span><br>       <span class="hljs-keyword">return</span> x, e<br></code></pre></td></tr></table></figure>
<p><code>sparse_forward()</code> 和 <code>dense_forward()</code> 方法分别执行稀疏表示和稠密模式下的前向传播。各张量的形状均已注释。</p>
<h3 id="out-layer"><code>out_layer</code></h3>
<p>out_layer（输出层）是 <strong>GNN Encoder 的最后一层“输出头”</strong>，负责接收GNN 主干网络（backbone）处理后的高维节点和边嵌入，并将它们转换成任务所需的最终预测格式（分类 logits）。</p>
<h4 id="base-py-2"><code>base.py</code></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">U2DCOOutLayer</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, hidden_dim: <span class="hljs-built_in">int</span>, out_channels: <span class="hljs-built_in">int</span>, sparse: <span class="hljs-built_in">bool</span></span>):<br>        <span class="hljs-built_in">super</span>(U2DCOOutLayer, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.hidden_dim = hidden_dim<br>        <span class="hljs-variable language_">self</span>.out_channels = out_channels<br>        <span class="hljs-variable language_">self</span>.sparse = sparse<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x: Tensor, e: Tensor</span>) -&gt; <span class="hljs-type">Sequence</span>[Tensor]:<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            [sparse]</span><br><span class="hljs-string">                x: (V, H)</span><br><span class="hljs-string">                e: (E, H)</span><br><span class="hljs-string">                t: (H)</span><br><span class="hljs-string">            [dense]</span><br><span class="hljs-string">                x: (B, V, H) </span><br><span class="hljs-string">                e: (B, V, V, H) </span><br><span class="hljs-string">                t: (H) </span><br><span class="hljs-string">        Return:</span><br><span class="hljs-string">            [sparse]</span><br><span class="hljs-string">                x: (V, out_channels)</span><br><span class="hljs-string">                e: (E, out_channels)</span><br><span class="hljs-string">                t: (H)</span><br><span class="hljs-string">            [dense]</span><br><span class="hljs-string">                x: (B, out_channels, V) </span><br><span class="hljs-string">                e: (B, out_channels, V, V) </span><br><span class="hljs-string">                t: (H) </span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.sparse:<br>            <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.sparse_forward(x, e)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.dense_forward(x, e)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">sparse_forward</span>(<span class="hljs-params">self, x: Tensor, e: Tensor</span>) -&gt; <span class="hljs-type">Sequence</span>[Tensor]:<br>        <span class="hljs-keyword">raise</span> NotImplementedError(<br>            <span class="hljs-string">&quot;``sparse_forward`` is required to implemented in subclasses.&quot;</span><br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">dense_forward</span>(<span class="hljs-params">self, x: Tensor, e: Tensor</span>) -&gt; <span class="hljs-type">Sequence</span>[Tensor]:<br>        <span class="hljs-keyword">raise</span> NotImplementedError(<br>            <span class="hljs-string">&quot;``dense_forward`` is required to implemented in subclasses.&quot;</span><br>        )<br></code></pre></td></tr></table></figure>
<p><code>U2DCOOutLayer</code> 定义了一个输出层的基类。初始化函数中，<code>out_channels</code> 是本层输出的特征维度，对于分类任务就是类别的数量。比如，对于边是否属于最优路径的二分类，<code>out_channels</code> 就是 2。<code>forward()</code> 方法根据稀疏 / 稠密表示进行分发，具体方法未实现。</p>
<h4 id="edge-py"><code>edge.py</code></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">EdgeOutLayer</span>(<span class="hljs-title class_ inherited__">U2DCOOutLayer</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, hidden_dim: <span class="hljs-built_in">int</span>, out_channels: <span class="hljs-built_in">int</span>, sparse: <span class="hljs-built_in">bool</span></span>):<br>        <span class="hljs-built_in">super</span>(EdgeOutLayer, <span class="hljs-variable language_">self</span>).__init__(hidden_dim, out_channels, sparse)<br>        <span class="hljs-variable language_">self</span>.e_norm = GroupNorm32(<span class="hljs-number">32</span>, hidden_dim)<br>        <span class="hljs-variable language_">self</span>.e_out = nn.Conv2d(hidden_dim, out_channels, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>
<p><code>EdgeOutLayer</code> 是对 <code>U2DCOOutLayer</code> 在选边问题上的具体实现，其接收 GNN 主干网络输出的高维节点和边嵌入，对<strong>边嵌入</strong>进行最终的加工处理（归一化和线性变换），并将其投影到任务所需的输出维度（logits），从而为每一条边预测其属于解的概率分数。</p>
<p>初始化部分，定义了 <code>self.e_norm</code> 和 <code>self.e_out</code> 两个层。</p>
<ul>
<li><code>self.e_norm</code>：<strong>使用 GroupNorm</strong>，这是 BatchNorm 和 LayerNorm 的一种折中方案。<code>GroupNorm32(32, hidden_dim)</code> 的含义是，<strong>将单个样本的所有 <code>hidden_dim</code> 个通道分成 32 个组，在每个组的内部进行归一化</strong>。这一步可以稳定特征分布，使得后续的线性变换更容易学习，从而加速了模型的收敛。具体的介绍可以参考 <a href="https://cny123222.github.io/2025/08/25/Batch-Layer-or-Instance-Normalization/">Batch, Layer, or Instance Normalization?</a> 这篇博客。</li>
<li><code>self.e_out</code>：使用 <strong>1x1 卷积</strong>，其实等价于<strong>一个作用于每个像素点的全连接层</strong>。当 1x1 卷积核滑到图片上的任何一个像素 <code>(i, j)</code> 时，它会看到这个像素点上的所有 <code>hidden_dim</code> 个通道的值，即一个长度为 <code>hidden_dim</code> 的向量。它用自己内部的权重（一个 <code>out_channels</code> x <code>hidden_dim</code> 的矩阵）与这个 <code>hidden_dim</code> 维向量进行一次矩阵乘法，输出一个 <code>out_channels</code> 维的新向量。这个过程对于每一个像素点 <code>(i, j)</code> 都是独立进行的，并且使用的都是同一套卷积核权重。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sparse_forward</span>(<span class="hljs-params">self, x: Tensor, e: Tensor</span>) -&gt; <span class="hljs-type">Sequence</span>[Tensor]:<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        x: (V, H); e: (E, H);</span><br><span class="hljs-string">    Return:</span><br><span class="hljs-string">        x: Any(not used); e: (E, out_channels);</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    nodes_num = x.shape[<span class="hljs-number">0</span>]<br>    hidden_dim = e.shape[<span class="hljs-number">1</span>]<br>    edges_num = e.shape[<span class="hljs-number">0</span>]<br>    e = e.reshape(<span class="hljs-number">1</span>, nodes_num, -<span class="hljs-number">1</span>, hidden_dim).permute((<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>))<br>    e: Tensor = <span class="hljs-variable language_">self</span>.e_out(<span class="hljs-variable language_">self</span>.e_norm(e))<br>    e = e.reshape(-<span class="hljs-number">1</span>, edges_num).permute((<span class="hljs-number">1</span>, <span class="hljs-number">0</span>))<br>    <span class="hljs-keyword">return</span> x, e<br></code></pre></td></tr></table></figure>
<p><code>sparse_forward()</code> 方法是稀疏图上的实现。首先，将边嵌入变形为 <code>(1, V, sparse_factor, H)</code>，再交换为 <code>(1, H, V, sparse_factor)</code>，这是 PyTorch <code>Conv2d</code> 所需的 <code>(Batch, Channel, Height, Width)</code> 格式。依次通过归一化层和 1x1 卷积层，得到预测 logits，形状为 <code>(1, out_channels, V, sparse_factor)</code>。最后，将 <code>e</code> 变形回 <code>(E, out_channels)</code> 的格式，返回结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">dense_forward</span>(<span class="hljs-params">self, x: Tensor, e: Tensor</span>) -&gt; <span class="hljs-type">Sequence</span>[Tensor]:<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        x: (B, V, H); e: (B, V, V, H);</span><br><span class="hljs-string">    Return:</span><br><span class="hljs-string">        x: (B, out_channels, V); e: Any(not used);</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    e = <span class="hljs-variable language_">self</span>.e_out(<span class="hljs-variable language_">self</span>.e_norm(e.permute((<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)))) <span class="hljs-comment"># (B, 2, V, V)</span><br>    <span class="hljs-keyword">return</span> x, e<br></code></pre></td></tr></table></figure>
<p><code>dense_forward()</code> 方法是稠密图上的实现。将输入 <code>e</code> 的形状从 <code>(B, V, V, H)</code> 调整为 <code>(B, H, V, V)</code>，依次通过归一化层和 1x1 卷积层，得到预测 logits，形状为 <code>(B, out_channels, V, V)</code>，返回结果。</p>
<h4 id="node-py"><code>node.py</code></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">NodeOutLayer</span>(<span class="hljs-title class_ inherited__">U2DCOOutLayer</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, hidden_dim: <span class="hljs-built_in">int</span>, out_channels: <span class="hljs-built_in">int</span>, sparse: <span class="hljs-built_in">bool</span></span>):<br>        <span class="hljs-built_in">super</span>(NodeOutLayer, <span class="hljs-variable language_">self</span>).__init__(hidden_dim, out_channels, sparse)<br>        <span class="hljs-variable language_">self</span>.x_norm = GroupNorm32(<span class="hljs-number">32</span>, hidden_dim)<br>        <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.sparse:<br>            <span class="hljs-variable language_">self</span>.x_out = nn.Conv2d(hidden_dim, out_channels, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-variable language_">self</span>.x_out = nn.Linear(hidden_dim, out_channels, bias=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>
<p><code>NodeOutLayer</code> 是对 <code>U2DCOOutLayer</code> 在选点问题上的具体实现，其接收 GNN 主干网络输出的高维节点和边嵌入，对<strong>节点嵌入</strong>进行最终的加工处理（归一化和线性变换），并将其投影到任务所需的输出维度（logits），从而为每一条节点预测其属于解的概率分数。</p>
<p>初始化部分与 <code>EdgeOutLayer</code> 类似。不同之处是，稠密模式下 <code>self.x_out</code> 采用线性层而不是 1x1 卷积层。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sparse_forward</span>(<span class="hljs-params">self, x: Tensor, e: Tensor</span>) -&gt; <span class="hljs-type">Sequence</span>[Tensor]:<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        x: (V, H); e: (E, H);</span><br><span class="hljs-string">    Return:</span><br><span class="hljs-string">        x: (V, out_channels); e: Any(not used);</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    nodes_num, hidden_dim = x.shape<br>    x = x.reshape(<span class="hljs-number">1</span>, nodes_num, -<span class="hljs-number">1</span>, hidden_dim).permute((<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>))<br>    x: Tensor = <span class="hljs-variable language_">self</span>.x_out(<span class="hljs-variable language_">self</span>.x_norm(x))<br>    x = x.reshape(-<span class="hljs-number">1</span>, nodes_num).permute((<span class="hljs-number">1</span>, <span class="hljs-number">0</span>))<br>    <span class="hljs-keyword">return</span> x, e<br></code></pre></td></tr></table></figure>
<p>和 <code>EdgeOutLayer</code> 的 <code>sparse_forward()</code> 方法几乎一样，只是将操作对象从 <code>e</code> 变成了 <code>x</code>，在此从略。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">dense_forward</span>(<span class="hljs-params">self, x: Tensor, e: Tensor</span>) -&gt; <span class="hljs-type">Sequence</span>[Tensor]:<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        x: (B, V, H); e: (B, V, V, H);</span><br><span class="hljs-string">    Return:</span><br><span class="hljs-string">        x: (B, out_channels, V); e: Any(not used);</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    x = <span class="hljs-variable language_">self</span>.x_norm(x.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>)) <span class="hljs-comment"># (B, H, V)</span><br>    x = x.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>) <span class="hljs-comment"># (B, V, H)</span><br>    x = <span class="hljs-variable language_">self</span>.x_out(x) <span class="hljs-comment"># (B, V, out_channels)</span><br>    x = x.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>) <span class="hljs-comment"># (B, out_channels, V)</span><br>    <span class="hljs-keyword">return</span> x, e<br></code></pre></td></tr></table></figure>
<p>将输入 <code>x</code> 的维度 <code>(B, V, H)</code> 交换为 <code>(B, H, V)</code>（因为 PyTorch通常约定 <code>(Batch, Channel, ...)</code> 的维度顺序），进行归一化，再将维度换回 <code>(B, V, H)</code>。接着，经过线性层，形状变为 <code>(B, V, out_channels)</code>，最后将维度换为 <code>(B, out_channels, V)</code>。</p>
<h3 id="encoder"><code>encoder</code></h3>
<p>Encoder 是整个 GNN 模型的核心部分，输入节点嵌入和边嵌入，输出最终的 heatmap。Encoder 的骨干网络是 GNN，其基本组成单元是 GNN 层，多个 GNN 层组成 GNN 块，再加上 Embedder 和 OutLayer 组成完整的 Encoder。</p>
<h4 id="gnn-encoder-py"><code>gnn_encoder.py</code></h4>
<p><code>GNNEncoder</code> 根据给定的任务（task）、数据格式（sparse/dense）和网络结构配置（block_layers），自动构建一个从数据嵌入、多层图消息传递到最终预测输出的完整 GNN 流水线，并执行前向传播。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">GNNEncoder</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        task: <span class="hljs-built_in">str</span>,</span><br><span class="hljs-params">        sparse: <span class="hljs-built_in">bool</span>,</span><br><span class="hljs-params">        block_layers: <span class="hljs-type">Sequence</span>[<span class="hljs-built_in">int</span>],</span><br><span class="hljs-params">        hidden_dim: <span class="hljs-built_in">int</span> = <span class="hljs-number">256</span>, </span><br><span class="hljs-params">        aggregation: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;sum&quot;</span>, </span><br><span class="hljs-params">        norm: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;layer&quot;</span>,</span><br><span class="hljs-params">        learn_norm: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">True</span>, </span><br><span class="hljs-params">        track_norm: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span></span><br><span class="hljs-params">    </span>):<br>        <span class="hljs-built_in">super</span>(GNNEncoder, <span class="hljs-variable language_">self</span>).__init__()<br>        <br>        <span class="hljs-comment"># embedder and out_layer</span><br>        <span class="hljs-variable language_">self</span>.task = task<br>        <span class="hljs-variable language_">self</span>.embedder = get_embedder_by_task(task)(hidden_dim, sparse)<br>        <span class="hljs-variable language_">self</span>.out_layer = get_out_layer_by_task(task)(hidden_dim, <span class="hljs-number">2</span>, sparse)<br><br>        <span class="hljs-comment"># asym</span><br>        <span class="hljs-keyword">if</span> task <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;ATSP&quot;</span>]:<br>            asym = <span class="hljs-literal">True</span><br>        <span class="hljs-keyword">else</span>:<br>            asym = <span class="hljs-literal">False</span><br>            <br>        <span class="hljs-comment"># gnn blocks</span><br>        <span class="hljs-keyword">if</span> sparse:<br>            <span class="hljs-comment"># gnn sparse blocks</span><br>            <span class="hljs-variable language_">self</span>.blocks = nn.ModuleList([<br>                GNNSparseBlock(<br>                    num_layers=num_layers,<br>                    hidden_dim=hidden_dim,<br>                    aggregation=aggregation,<br>                    norm=norm,<br>                    learn_norm=learn_norm,<br>                    track_norm=track_norm,<br>                    asym=asym<br>                ) <span class="hljs-keyword">for</span> num_layers <span class="hljs-keyword">in</span> block_layers<br>            ])<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># gnn dense blocks</span><br>            <span class="hljs-variable language_">self</span>.blocks = nn.ModuleList([<br>                GNNDenseBlock(<br>                    num_layers=num_layers,<br>                    hidden_dim=hidden_dim,<br>                    aggregation=aggregation,<br>                    norm=norm,<br>                    learn_norm=learn_norm,<br>                    track_norm=track_norm,<br>                    asym=asym<br>                ) <span class="hljs-keyword">for</span> num_layers <span class="hljs-keyword">in</span> block_layers<br>            ])<br></code></pre></td></tr></table></figure>
<p>首先根据任务，获取对应的 Embedder 和 OutLayer。接着，根据是稀疏图还是稠密图，创建不同的 GNN 块。具体的块数及每块中 GNN 层数由 <code>block_layers</code> 决定，比如 <code>block_layer = [4, 4]</code> 表示创建 2 个 GNN 块，每个块内部有 4 个 GNN 层。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params"></span><br><span class="hljs-params">    self, task: <span class="hljs-built_in">str</span>, x: Tensor, e: Tensor, edge_index: Tensor</span><br><span class="hljs-params"></span>) -&gt; <span class="hljs-type">Sequence</span>[Tensor]:<br>    <span class="hljs-keyword">if</span> task <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;ATSP&quot;</span>]:<br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.asym_forward(<br>            task=task, x=x, e=e, edge_index=edge_index<br>        )<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.sym_forward(<br>            task=task, x=x, e=e, edge_index=edge_index<br>        )<br></code></pre></td></tr></table></figure>
<p><code>forward()</code> 方法是前向传播的主入口。如果是 ATSP 问题，分发至处理非对称问题的 <code>asym_forward()</code> 方法；否则，分发至处理对称问题的 <code>sym_forward()</code> 方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sym_forward</span>(<span class="hljs-params"></span><br><span class="hljs-params">    self, task: <span class="hljs-built_in">str</span>, x: Tensor, e: Tensor, edge_index: Tensor</span><br><span class="hljs-params"></span>) -&gt; <span class="hljs-type">Sequence</span>[Tensor]:<br>    <span class="hljs-comment"># embedder</span><br>    x, e = <span class="hljs-variable language_">self</span>.embedder(x, e)<br><br>    <span class="hljs-comment"># gnn blocks</span><br>    <span class="hljs-keyword">for</span> gnn_block <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.blocks:<br>        gnn_block: <span class="hljs-type">Union</span>[GNNDenseBlock, GNNSparseBlock]<br>        x, e = gnn_block.forward(x=x, e=e, edge_index=edge_index)<br><br>    <span class="hljs-comment"># out layer</span><br>    x, e = <span class="hljs-variable language_">self</span>.out_layer(x, e)<br><br>    <span class="hljs-comment"># return</span><br>    <span class="hljs-keyword">return</span> x, e<br></code></pre></td></tr></table></figure>
<p>（此处省略类似的 <code>asym_forward</code> 方法）</p>
<p>在前向传播函数中，Encoder 接收到输入数据 <code>x, e, edge_index</code>，先通过 <strong>Embedder</strong>，将其转换为高维的节点和边嵌入。再将嵌入后的 <code>x</code> 和 <code>e</code> 依次送入每一个 <strong>GNN 块</strong>，数据在每个块数据会进行多次消息传递和更新，且每一个块的输出都是下一个块的输入，特征信息逐层被提纯和丰富。最终，将经过多层 GNN 处理后的节点和边嵌入，送入 <strong>OutLayer</strong>，转换成任务所需的最终输出格式（如二维的分类 logits），返回最终的节点和边预测。</p>
<h4 id="gnn-layer-py"><code>gnn_layer.py</code></h4>
<p>这个文件提供了一套模块化的、可堆叠的 <strong>GNN 层</strong>，用于在图的节点和边之间进行迭代式的消息传递和特征更新。它为稀疏图和稠密图分别提供了实现，并封装成了易于使用的 <strong>GNN 块</strong>。</p>
<p>我们先看<strong>稀疏图的 GNN 层和 GNN 块</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">GNNSparseLayer</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self, </span><br><span class="hljs-params">        hidden_dim: <span class="hljs-built_in">int</span>, </span><br><span class="hljs-params">        aggregation: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;sum&quot;</span>, </span><br><span class="hljs-params">        norm: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;batch&quot;</span>,</span><br><span class="hljs-params">        learn_norm: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">True</span>,</span><br><span class="hljs-params">        track_norm: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span>,</span><br><span class="hljs-params">        asym: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span></span><br><span class="hljs-params">    </span>):<br>        <span class="hljs-built_in">super</span>(GNNSparseLayer, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.hidden_dim = hidden_dim<br>        <span class="hljs-variable language_">self</span>.aggregation = aggregation<br>        <br>        <span class="hljs-comment"># Linear Layer for nodes</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> asym:<br>            <span class="hljs-variable language_">self</span>.U = nn.Linear(hidden_dim, hidden_dim, bias=<span class="hljs-literal">True</span>)<br>            <span class="hljs-variable language_">self</span>.V = nn.Linear(hidden_dim, hidden_dim, bias=<span class="hljs-literal">True</span>)<br>            <span class="hljs-variable language_">self</span>.A = nn.Linear(hidden_dim, hidden_dim, bias=<span class="hljs-literal">True</span>)<br>            <span class="hljs-variable language_">self</span>.B = nn.Linear(hidden_dim, hidden_dim, bias=<span class="hljs-literal">True</span>)<br>        <br>        <span class="hljs-comment"># Linear Layer for edges</span><br>        <span class="hljs-keyword">if</span> asym:<br>            <span class="hljs-variable language_">self</span>.D = nn.Linear(<span class="hljs-number">2</span>, hidden_dim, bias=<span class="hljs-literal">True</span>)<br>            <span class="hljs-variable language_">self</span>.F = nn.Linear(<span class="hljs-number">2</span> * hidden_dim, hidden_dim, bias=<span class="hljs-literal">True</span>)<br>            <span class="hljs-variable language_">self</span>.E1 = nn.Linear(hidden_dim, hidden_dim, bias=<span class="hljs-literal">True</span>)<br>            <span class="hljs-variable language_">self</span>.E2 = nn.Linear(hidden_dim, hidden_dim, bias=<span class="hljs-literal">True</span>)<br>            <span class="hljs-variable language_">self</span>.C = nn.Linear(hidden_dim, hidden_dim, bias=<span class="hljs-literal">True</span>)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-variable language_">self</span>.C = nn.Linear(hidden_dim, hidden_dim, bias=<span class="hljs-literal">True</span>)<br>        <br>        <span class="hljs-comment"># Normalization for nodes and edges</span><br>        <span class="hljs-keyword">if</span> norm == <span class="hljs-string">&quot;batch&quot;</span>:<br>            <span class="hljs-variable language_">self</span>.norm_x = nn.BatchNorm1d(hidden_dim, affine=learn_norm, track_running_stats=track_norm)<br>            <span class="hljs-variable language_">self</span>.norm_e = nn.BatchNorm1d(hidden_dim, affine=learn_norm, track_running_stats=track_norm)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-variable language_">self</span>.norm_x = nn.LayerNorm(hidden_dim, elementwise_affine=learn_norm)<br>            <span class="hljs-variable language_">self</span>.norm_e = nn.LayerNorm(hidden_dim, elementwise_affine=learn_norm)<br></code></pre></td></tr></table></figure>
<p><code>GNNSparseLayer</code> 是稀疏图上的 GNN 层实现。初始化部分，在非对称 <code>asym</code> 和对称 <code>not asym</code> 模式下，分别初始化了一些线性层和归一化层。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x: Tensor, e: Tensor, edge_index: Tensor</span>) -&gt; <span class="hljs-type">Sequence</span>[Tensor]:<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        x: (V, H) Node features; e: (E, H) Edge features</span><br><span class="hljs-string">        edge_index: (2, E) Tensor with edges representing connections from source to target nodes.</span><br><span class="hljs-string">    Returns:</span><br><span class="hljs-string">        Updated x and e after one layer of GNN.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    nodes_num = x.shape[<span class="hljs-number">0</span>] <span class="hljs-comment"># Total number of nodes</span><br>    <br>    <span class="hljs-comment"># Linear transformation for node embeddings</span><br>    Ux: Tensor = <span class="hljs-variable language_">self</span>.U(x) <span class="hljs-comment"># (V, H)</span><br>    <br>    <span class="hljs-comment"># Aggregate neighbor information for edges</span><br>    Vx = <span class="hljs-variable language_">self</span>.V(x[edge_index[<span class="hljs-number">1</span>]]) <span class="hljs-comment"># (E, H)</span><br>    <br>    <span class="hljs-comment"># Message passing from nodes to edges</span><br>    Ax = <span class="hljs-variable language_">self</span>.A(x) <span class="hljs-comment"># (V, H), source</span><br>    Bx = <span class="hljs-variable language_">self</span>.B(x) <span class="hljs-comment"># (V, H), target</span><br>    <br>    <span class="hljs-comment"># Update edge features</span><br>    Ce = <span class="hljs-variable language_">self</span>.C(e) <span class="hljs-comment"># (E, H)</span><br>    e = Ax[edge_index[<span class="hljs-number">0</span>]] + Bx[edge_index[<span class="hljs-number">1</span>]] + Ce <span class="hljs-comment"># (E, H)</span><br>        <br>    <span class="hljs-comment"># Sigmoid gates for edge features</span><br>    gates = torch.sigmoid(e) <span class="hljs-comment"># (E, H)</span><br>    <br>    <span class="hljs-comment"># Aggregate messages for node embeddings</span><br>    x = Ux + <span class="hljs-variable language_">self</span>.aggregate(Vx, gates, edge_index, nodes_num) <span class="hljs-comment"># (V, H)</span><br><br>    <span class="hljs-comment"># Apply normalization and activation</span><br>    x = F.relu(<span class="hljs-variable language_">self</span>.norm_x(x)) <span class="hljs-comment"># (V, H)</span><br>    e = F.relu(<span class="hljs-variable language_">self</span>.norm_e(e)) <span class="hljs-comment"># (E, H)</span><br>    <br>    <span class="hljs-keyword">return</span> x, e<br></code></pre></td></tr></table></figure>
<p>（此处省略类似的 <code>asym_forward</code> 函数）</p>
<p>这部分进行了<strong>消息传递神经网络</strong>的实现，主要更新了节点和边特征。</p>
<ul>
<li>对于<strong>边特征的更新</strong>：每条边的新特征 <code>e</code> 由三部分相加构成，分别是源节点 <code>i</code> 的消息 <code>Ax[edge_index[0]]</code>、目标节点 <code>j</code> 的消息 <code>Bx[edge_index[1]]</code> 和边自身消息 <code>Ce</code>。</li>
<li>对于<strong>节点特征的更新</strong>：使用了<strong>聚合带门控的消息</strong>，具体公式可以看论文。每个节点的新特征 <code>x</code> 由自身更新后的信息 <code>Ux</code> 和所有邻居聚合的消息 <code>self.aggregate(...)</code> 两部分相加构成。门控 <code>gates</code> 由刚更新的边特征经过 Sigmoid 得到。如果 <code>gates</code> 的某个维度接近 1，意味着这条边在这个维度上很重要，它传递的消息应该被放行；如果接近0，则消息被阻断。这样，模型可以学习性地控制信息流，将目标节点的信息 <code>Vx</code> 选择性地聚合到源节点上。</li>
</ul>
<p>最后，将更新后的节点和边特征分贝通过归一化层和 ReLU 激活函数，并返回结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">aggregate</span>(<span class="hljs-params"></span><br><span class="hljs-params">    self, Vx: Tensor, gates: Tensor, edge_index: Tensor, nodes_num: <span class="hljs-built_in">int</span></span><br><span class="hljs-params"></span>) -&gt; Tensor:<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        Vx: (E, H); gates: (E, H); edge_index: (2, E)</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Returns:</span><br><span class="hljs-string">        node feature: (V, H)</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    sparseVh = SparseTensor(<br>        row=edge_index[<span class="hljs-number">0</span>],<br>        col=edge_index[<span class="hljs-number">1</span>],<br>        value=Vx * gates,<br>        sparse_sizes=(nodes_num, nodes_num)<br>    )<br>    <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.aggregation == <span class="hljs-string">&quot;mean&quot;</span>:<br>        <span class="hljs-keyword">return</span> sparse_mean(sparseVh, dim=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">elif</span> <span class="hljs-variable language_">self</span>.aggregation == <span class="hljs-string">&quot;max&quot;</span>:<br>        <span class="hljs-keyword">return</span> sparse_max(sparseVh, dim=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> sparse_sum(sparseVh, dim=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>
<p>这是刚才函数中 <code>aggregate</code> 的具体实现，<strong>调用了 <code>torch-sparse</code> 库</strong>，这是一个非常巧妙的做法。这个函数的作用是：<strong>对于每个目标节点，汇聚所有邻居的信息</strong>。</p>
<p>首先我们将 COO 格式的图表示<strong>转换成一个高度优化的 <code>SparseTensor</code> 对象</strong>。这个对象可以想象成一个形状 <code>(V, V, H)</code> 的虚拟矩阵，每一行代表源节点，每一列代表目标节点。该矩阵的大部分位置是空的，只有在 <code>edge_index</code> 指定的位置上，才填充了 <code>value</code> 中对应的信息（这里是形状 <code>(H,)</code> 的消息向量）。以 <code>self.aggregation == &quot;sum&quot;</code> 为例，<code>sparse_sum(sparseVh, dim=1)</code> 对这个矩阵按列（<code>dim=1</code>）聚合，即将每一列的所有向量求和，得到一个新向量。这样，<strong>对每个目标节点，我们都获得了所有邻居源节点传来的消息之和</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">GNNSparseBlock</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self, </span><br><span class="hljs-params">        num_layers: <span class="hljs-built_in">int</span>, </span><br><span class="hljs-params">        hidden_dim: <span class="hljs-built_in">int</span>, </span><br><span class="hljs-params">        aggregation: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;sum&quot;</span>, </span><br><span class="hljs-params">        norm: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;layer&quot;</span>,</span><br><span class="hljs-params">        learn_norm: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">True</span>, </span><br><span class="hljs-params">        track_norm: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span>,</span><br><span class="hljs-params">        asym: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span></span><br><span class="hljs-params">    </span>):<br>        <span class="hljs-built_in">super</span>(GNNSparseBlock, <span class="hljs-variable language_">self</span>).__init__()<br>        <br>        <span class="hljs-comment"># gnn layer</span><br>        <span class="hljs-variable language_">self</span>.layers = nn.ModuleList([<br>            GNNSparseLayer(hidden_dim, aggregation, norm, learn_norm, track_norm, asym)<br>            <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_layers)<br>        ])<br>        <br>        <span class="hljs-comment"># per layer out</span><br>        <span class="hljs-variable language_">self</span>.per_layer_out = nn.ModuleList([<br>            nn.Sequential(<br>                nn.LayerNorm(hidden_dim, elementwise_affine=learn_norm),<br>                nn.SiLU(),<br>                zero_module(nn.Linear(hidden_dim, hidden_dim)),<br>            ) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_layers)<br>        ])<br></code></pre></td></tr></table></figure>
<p><code>num_layers</code> 个 <code>GNNSparseLayer</code> 堆叠形成 GNN 块 <code>self.layers</code>，在每层后还加入了层归一化 <code>nn.LayerNorm(...)</code>、激活函数 <code>nn.SiLU()</code> 和一个线性层。这个线性层的可学习参数初始化为 0，以便模型的平滑启动和渐进式学习。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x: Tensor, e: Tensor, edge_index: Tensor</span>) -&gt; <span class="hljs-type">Sequence</span>[Tensor]:<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        x: (V, H) Node features; </span><br><span class="hljs-string">        e: (E, H) Edge features;</span><br><span class="hljs-string">        edge_index: (2, E) Tensor with edges representing connections from source to target nodes.</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    Return:</span><br><span class="hljs-string">        updated features. x: (V, H); e: (E, H);</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># gnn layer</span><br>    <span class="hljs-keyword">for</span> layer, out_layer <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(<span class="hljs-variable language_">self</span>.layers, <span class="hljs-variable language_">self</span>.per_layer_out):<br>        x_in, e_in = x, e<br>        x, e = layer(x, e, edge_index)<br>        x = x + x_in<br>        e = e_in + out_layer(e)<br>    <br>    <span class="hljs-comment"># return</span><br>    <span class="hljs-keyword">return</span> x, e<br></code></pre></td></tr></table></figure>
<p>（此处省略类似的 <code>asym_forward</code> 函数）</p>
<p><code>x</code> 和 <code>e</code> 流经多层 GNN 层，并应用残差连接。注意，边特征 <code>e</code> 在残差连接的时候加入了非线性分支，先通过 <code>out_layer()</code>，再进行残差连接。</p>
<p>我们接着来看<strong>稠密图的 GNN 层和 GNN 块</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">GNNDenseLayer</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self, </span><br><span class="hljs-params">        hidden_dim: <span class="hljs-built_in">int</span>, </span><br><span class="hljs-params">        aggregation: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;sum&quot;</span>, </span><br><span class="hljs-params">        norm: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;batch&quot;</span>,</span><br><span class="hljs-params">        learn_norm: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">True</span>,</span><br><span class="hljs-params">        track_norm: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span>,</span><br><span class="hljs-params">        asym: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span></span><br><span class="hljs-params">    </span>):<br>        <span class="hljs-built_in">super</span>(GNNDenseLayer, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.hidden_dim = hidden_dim<br>        <span class="hljs-variable language_">self</span>.aggregation = aggregation<br>        <br>        <span class="hljs-comment"># Linear Layer for nodes</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> asym:<br>            <span class="hljs-variable language_">self</span>.U = nn.Linear(hidden_dim, hidden_dim, bias=<span class="hljs-literal">True</span>)<br>            <span class="hljs-variable language_">self</span>.V = nn.Linear(hidden_dim, hidden_dim, bias=<span class="hljs-literal">True</span>)<br>            <span class="hljs-variable language_">self</span>.A = nn.Linear(hidden_dim, hidden_dim, bias=<span class="hljs-literal">True</span>)<br>            <span class="hljs-variable language_">self</span>.B = nn.Linear(hidden_dim, hidden_dim, bias=<span class="hljs-literal">True</span>)<br>        <br>        <span class="hljs-comment"># Linear Layer for edges</span><br>        <span class="hljs-keyword">if</span> asym:<br>            <span class="hljs-variable language_">self</span>.D = nn.Linear(<span class="hljs-number">2</span>, hidden_dim, bias=<span class="hljs-literal">True</span>)<br>            <span class="hljs-variable language_">self</span>.F = nn.Linear(<span class="hljs-number">2</span> * hidden_dim, hidden_dim, bias=<span class="hljs-literal">True</span>)<br>            <span class="hljs-variable language_">self</span>.E1 = nn.Linear(hidden_dim, hidden_dim, bias=<span class="hljs-literal">True</span>)<br>            <span class="hljs-variable language_">self</span>.E2 = nn.Linear(hidden_dim, hidden_dim, bias=<span class="hljs-literal">True</span>)<br>            <span class="hljs-variable language_">self</span>.C = nn.Linear(hidden_dim, hidden_dim, bias=<span class="hljs-literal">True</span>)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-variable language_">self</span>.C = nn.Linear(hidden_dim, hidden_dim, bias=<span class="hljs-literal">True</span>)<br>        <br>        <span class="hljs-comment"># Normalization for nodes and edges</span><br>        <span class="hljs-keyword">if</span> asym:<br>            <span class="hljs-keyword">if</span> norm == <span class="hljs-string">&quot;batch&quot;</span>:<br>                <span class="hljs-variable language_">self</span>.norm_x1 = nn.BatchNorm1d(hidden_dim, affine=learn_norm, track_running_stats=track_norm)<br>                <span class="hljs-variable language_">self</span>.norm_x2 = nn.BatchNorm1d(hidden_dim, affine=learn_norm, track_running_stats=track_norm)<br>                <span class="hljs-variable language_">self</span>.norm_e = nn.BatchNorm1d(hidden_dim, affine=learn_norm, track_running_stats=track_norm)<br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-variable language_">self</span>.norm_x1 = nn.LayerNorm(hidden_dim, elementwise_affine=learn_norm)<br>                <span class="hljs-variable language_">self</span>.norm_x2 = nn.LayerNorm(hidden_dim, elementwise_affine=learn_norm)<br>                <span class="hljs-variable language_">self</span>.norm_e = nn.LayerNorm(hidden_dim, elementwise_affine=learn_norm)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">if</span> norm == <span class="hljs-string">&quot;batch&quot;</span>:<br>                <span class="hljs-variable language_">self</span>.norm_x = nn.BatchNorm1d(hidden_dim, affine=learn_norm, track_running_stats=track_norm)<br>                <span class="hljs-variable language_">self</span>.norm_e = nn.BatchNorm1d(hidden_dim, affine=learn_norm, track_running_stats=track_norm)<br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-variable language_">self</span>.norm_x = nn.LayerNorm(hidden_dim, elementwise_affine=learn_norm)<br>                <span class="hljs-variable language_">self</span>.norm_e = nn.LayerNorm(hidden_dim, elementwise_affine=learn_norm)<br></code></pre></td></tr></table></figure>
<p>与 <code>GNNSparseLayer</code> 的 <code>__init__()</code> 方法类似，定义了一些线性层和归一化层。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x: Tensor, e: Tensor, graph: Tensor</span>) -&gt; <span class="hljs-type">Sequence</span>[Tensor]:<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        x: (B, V, H) Node features; </span><br><span class="hljs-string">        e: (B, V, V, H) Edge features</span><br><span class="hljs-string">        graph: (B, V, V) Graph adjacency matrices</span><br><span class="hljs-string">    Returns:</span><br><span class="hljs-string">        Updated x and e after one layer of GNN.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    batch_size, nodes_num, hidden_dim = x.shape<br>    <br>    <span class="hljs-comment"># Linear transformation for node embeddings</span><br>    Ux: Tensor = <span class="hljs-variable language_">self</span>.U(x) <span class="hljs-comment"># (B, V, H)</span><br>    <br>    <span class="hljs-comment"># Aggregate neighbor information for edges</span><br>    Vx: Tensor = <span class="hljs-variable language_">self</span>.V(x) <span class="hljs-comment"># (B, V, H)</span><br>    Vx = Vx.unsqueeze(<span class="hljs-number">1</span>).expand(-<span class="hljs-number">1</span>, nodes_num, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>) <span class="hljs-comment"># (B, V, V, H)</span><br>    <br>    <span class="hljs-comment"># Message passing from nodes to edges</span><br>    Ax: Tensor = <span class="hljs-variable language_">self</span>.A(x) <span class="hljs-comment"># (B, V, H), source</span><br>    Bx: Tensor = <span class="hljs-variable language_">self</span>.B(x) <span class="hljs-comment"># (B, V, H), target</span><br>    <br>    <span class="hljs-comment"># Update edge features</span><br>    Ce = <span class="hljs-variable language_">self</span>.C(e) <span class="hljs-comment"># (B, V, V, H)</span><br>    e = Ax.unsqueeze(dim=<span class="hljs-number">1</span>) + Bx.unsqueeze(dim=<span class="hljs-number">2</span>) + Ce <span class="hljs-comment"># (B, V, V, H)</span><br>        <br>    <span class="hljs-comment"># Sigmoid gates for edge features</span><br>    gates = torch.sigmoid(e) <span class="hljs-comment"># (B, V, V, H)</span><br>    <br>    <span class="hljs-comment"># Aggregate messages for node embeddings</span><br>    x = Ux + <span class="hljs-variable language_">self</span>.aggregate(Vx, gates, graph) <span class="hljs-comment"># (B, V, H)</span><br><br>    <span class="hljs-comment"># Apply normalization and activation</span><br>    x = x.view(batch_size * nodes_num, hidden_dim) <span class="hljs-comment"># (B*V, H)</span><br>    x = F.relu(<span class="hljs-variable language_">self</span>.norm_x(x)).view(batch_size, nodes_num, hidden_dim) <span class="hljs-comment"># (B, V, H)</span><br>    e = e.view(batch_size * nodes_num * nodes_num, hidden_dim)<br>    e = F.relu(<span class="hljs-variable language_">self</span>.norm_e(e)).view(batch_size, nodes_num, nodes_num, hidden_dim) <span class="hljs-comment"># (B, V, V, H)</span><br>    <br>    <span class="hljs-keyword">return</span> x, e<br></code></pre></td></tr></table></figure>
<p>（此处省略类似的 <code>asym_forward</code> 函数）</p>
<p>与稀疏图上的 <code>forward()</code> 函数的作用相似，但实现不同。在输入上，<code>graph</code> 代替了 <code>edge_index</code>。</p>
<ul>
<li>对于<strong>边特征</strong>的更新：新的边特征还是由源节点消息、目标节点消息和边自身消息三部分相加而成。源节点消息为 <code>Ax.unsqueeze(dim=1)</code>，形状 <code>(B, 1, V, H)</code>；目标节点消息为 <code>Bx.unsqueeze(dim=2)</code>，形状 <code>(B, V, 1, H)</code>；边自身消息为 <code>Ce</code>，形状 <code>(B, V, V, H)</code>。Pytorch 的广播机制会将它们自动扩展为 <code>(B, V, V, H)</code> 的形状再相加。对于最终结果 <code>e</code> 的 <code>(b, i, j, h)</code> 位置，它的值是 <code>A(x_bj)[h] + B(x_bi)[h] + C(e_bij)[h]</code>。这实现了与稀疏版本 <code>A(x_j) + B(x_i) + C(e_ij)</code> 完全相同的计算逻辑。</li>
<li>对于<strong>节点特征</strong>的更新：先将节点消息 <code>Vx</code> 的形状扩展到 <code>(B, V, V, H)</code>。这意味着对于源节点 <code>i</code>，它从所有可能的邻居 <code>j</code> 那里收到的消息都是 <code>V(x_bj)</code>。接着，计算聚合带门控的消息，<code>self.aggregate(...)</code> 并与节点自身消息相加。</li>
</ul>
<p>最后，将 <code>x</code> 和 <code>e</code> 通过归一化和激活函数。注意，进行 <code>view</code> 操作变形的目的是，归一化层期望的输入形状是 <code>(N, C)</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">aggregate</span>(<span class="hljs-params">self, Vx: Tensor, gates: Tensor, graph: Tensor</span>) -&gt; Tensor:  <br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        Vx: (B, V, V, H); gates: (B, V, V, H); graph: (B, V, V)</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Returns:</span><br><span class="hljs-string">        node feature: (B, V, H)</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    Vx = Vx * gates<br>    <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.aggregation == <span class="hljs-string">&quot;mean&quot;</span>:<br>        <span class="hljs-keyword">return</span> torch.<span class="hljs-built_in">sum</span>(Vx, dim=<span class="hljs-number">2</span>) / (torch.<span class="hljs-built_in">sum</span>(graph, dim=<span class="hljs-number">2</span>).unsqueeze(-<span class="hljs-number">1</span>).type_as(Vx))<br>    <span class="hljs-keyword">elif</span> <span class="hljs-variable language_">self</span>.aggregation == <span class="hljs-string">&quot;max&quot;</span>:<br>        <span class="hljs-keyword">return</span> torch.<span class="hljs-built_in">max</span>(Vx, dim=<span class="hljs-number">2</span>)[<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> torch.<span class="hljs-built_in">sum</span>(Vx, dim=<span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure>
<p>这是稠密模式下的聚合函数。还是先将 <code>Vx</code> 与门控 <code>gates</code> 相乘，得到加权后的消息。以 <code>self.aggregation == &quot;sum&quot;</code> 为例，对每一个目标节点，对所有源节点的信息进行相加聚合，得到形状 <code>(B, V, H)</code> 的聚合消息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">GNNDenseBlock</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self, </span><br><span class="hljs-params">        num_layers: <span class="hljs-built_in">int</span>, </span><br><span class="hljs-params">        hidden_dim: <span class="hljs-built_in">int</span>, </span><br><span class="hljs-params">        aggregation: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;sum&quot;</span>, </span><br><span class="hljs-params">        norm: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;layer&quot;</span>,</span><br><span class="hljs-params">        learn_norm: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">True</span>, </span><br><span class="hljs-params">        track_norm: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span>,</span><br><span class="hljs-params">        asym: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span></span><br><span class="hljs-params">    </span>):<br>        <span class="hljs-built_in">super</span>(GNNDenseBlock, <span class="hljs-variable language_">self</span>).__init__()<br>        <br>        <span class="hljs-comment"># gnn layer</span><br>        <span class="hljs-variable language_">self</span>.layers = nn.ModuleList([<br>            GNNDenseLayer(hidden_dim, aggregation, norm, learn_norm, track_norm, asym)<br>            <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_layers)<br>        ])<br>        <br>        <span class="hljs-comment"># per layer out</span><br>        <span class="hljs-variable language_">self</span>.per_layer_out = nn.ModuleList([<br>            nn.Sequential(<br>                nn.LayerNorm(hidden_dim, elementwise_affine=learn_norm),<br>                nn.SiLU(),<br>                zero_module(nn.Linear(hidden_dim, hidden_dim)),<br>            ) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_layers)<br>        ])<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x: Tensor, e: Tensor, edge_index</span>) -&gt; <span class="hljs-type">Sequence</span>[Tensor]:<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            x: (B, V, H) Node features; </span><br><span class="hljs-string">            e: (B, V, V, H) Edge features;</span><br><span class="hljs-string">            edge_index: None</span><br><span class="hljs-string">            </span><br><span class="hljs-string">        Return:</span><br><span class="hljs-string">            updated features. x: (B, V, H); e: (B, V, V, H);</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        batch_size, nodes_num, _ = x.shape<br>        graph = torch.ones(size=(batch_size, nodes_num, nodes_num)).to(x.device)<br>        <br>        <span class="hljs-comment"># gnn layer</span><br>        <span class="hljs-keyword">for</span> layer, out_layer <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(<span class="hljs-variable language_">self</span>.layers, <span class="hljs-variable language_">self</span>.per_layer_out):<br>            x_in, e_in = x, e<br>            x, e = layer(x, e, graph)<br>            x = x + x_in<br>            e = e_in + out_layer(e)<br>        <br>        <span class="hljs-comment"># return</span><br>        <span class="hljs-keyword">return</span> x, e<br></code></pre></td></tr></table></figure>
<p>（此处省略类似的 <code>asym_forward</code> 方法）</p>
<p>这与 <code>GNNSparseBlock</code> 的 <code>__init__()</code> 和 <code>forward()</code> 方法基本一致，在此不再赘述。</p>
<h3 id="decoder"><code>decoder</code></h3>
<p>Decoder 负责将 GNN 模型生成的 heatmap 解码成具体问题的解。</p>
<h4 id="base-py-3"><code>base.py</code></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">GNN4CODecoder</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-keyword">pass</span><br></code></pre></td></tr></table></figure>
<p><code>GNN4CODecoder</code> 是一个 Decoder 的基类，它能够处理不同任务（选边 / 选点）和不同数据格式（稀疏 / 稠密）的解码请求，并将具体的解码算法委托给子类实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sparse_decode</span>(<span class="hljs-params"></span><br><span class="hljs-params">    self, heatmap: Tensor, task: <span class="hljs-built_in">str</span>, x: Tensor, e: Tensor, </span><br><span class="hljs-params">    edge_index: Tensor, graph_list: <span class="hljs-type">List</span>[Tensor], ground_truth: Tensor, </span><br><span class="hljs-params">    nodes_num_list: <span class="hljs-built_in">list</span>, edges_num_list: <span class="hljs-built_in">list</span>, return_cost: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span></span><br><span class="hljs-params"></span>) -&gt; <span class="hljs-type">Union</span>[<span class="hljs-type">List</span>[np.ndarray], np.floating]:<br>    <span class="hljs-comment"># get solutions</span><br>    solutions = <span class="hljs-built_in">list</span>()<br>    <span class="hljs-keyword">if</span> task <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;MIS&quot;</span>, <span class="hljs-string">&quot;MVC&quot;</span>, <span class="hljs-string">&quot;MCl&quot;</span>]:<br>        begin_idx = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(graph_list)):<br>            end_idx = begin_idx + nodes_num_list[idx]<br>            solutions.append(<span class="hljs-variable language_">self</span>._node_sparse_decode(<br>                heatmap=heatmap[begin_idx:end_idx], <br>                graph=graph_list[idx]<br>            ))<br>            begin_idx = end_idx<br>    <span class="hljs-keyword">elif</span> task <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;MCut&quot;</span>]:<br>        node_begin_idx = <span class="hljs-number">0</span><br>        edge_begin_idx = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(edges_num_list)):<br>            node_end_idx = node_begin_idx + edges_num_list[idx]<br>            edge_end_idx = edge_begin_idx + edges_num_list[idx]<br>            solutions.append(<span class="hljs-variable language_">self</span>._node_sparse_decode(<br>                heatmap=heatmap[node_begin_idx:node_end_idx],<br>                graph=graph_list[idx], <br>                edge_index=edge_index[:, edge_begin_idx:edge_end_idx],<br>            ))<br>            node_begin_idx = node_end_idx<br>            edge_begin_idx = edge_end_idx<br>    <span class="hljs-keyword">elif</span> task <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;TSP&quot;</span>]:<br>        node_begin_idx = <span class="hljs-number">0</span><br>        edge_begin_idx = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(edges_num_list)):<br>            node_end_idx = node_begin_idx + edges_num_list[idx]<br>            edge_end_idx = edge_begin_idx + edges_num_list[idx]<br>            solutions.append(<span class="hljs-variable language_">self</span>._edge_sparse_decode(<br>                heatmap=heatmap[edge_begin_idx:edge_end_idx], <br>                x=x[node_begin_idx:node_end_idx],<br>                edge_index=edge_index[:, edge_begin_idx:edge_end_idx],<br>                nodes_num=nodes_num_list[idx]<br>            ))<br>            node_begin_idx = node_end_idx<br>            edge_begin_idx = edge_end_idx<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">raise</span> NotImplementedError()<br>    <br>    <span class="hljs-comment"># check if return cost</span><br>    <span class="hljs-keyword">if</span> return_cost:<br>        <span class="hljs-keyword">if</span> task <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;MIS&quot;</span>, <span class="hljs-string">&quot;MVC&quot;</span>, <span class="hljs-string">&quot;MCl&quot;</span>]:<br>            costs = [<span class="hljs-built_in">sum</span>(sol) <span class="hljs-keyword">for</span> sol <span class="hljs-keyword">in</span> solutions]<br>            costs = np.average(np.array(costs))<br>        <span class="hljs-keyword">elif</span> task <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;MCut&quot;</span>]:<br>            edge_index = to_numpy(edge_index)<br>            mcut_solver = MCutSolver()<br>            mcut_solver.from_adj_matrix(<br>                adj_matrix=[to_numpy(g) <span class="hljs-keyword">for</span> g <span class="hljs-keyword">in</span> graph_list],<br>                nodes_label=solutions<br>            )<br>            costs = mcut_solver.evaluate()<br>        <span class="hljs-keyword">elif</span> task <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;TSP&quot;</span>]:<br>            tsp_solver = TSPSolver()<br>            tsp_solver.from_data(<br>                points=to_numpy(x), tours=solutions<br>            )<br>            costs = tsp_solver.evaluate()<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> NotImplementedError()<br>        <span class="hljs-keyword">return</span> costs<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> solutions<br></code></pre></td></tr></table></figure>
<p><code>sparse_decode()</code> 方法是稀疏图解码调用的外部接口，其作用是<strong>解码一个批次的、以稀疏格式表示的数据</strong>。主要的难点在于，<strong>稀疏数据在输入时被合并成了一个大图，现在需要被拆分开</strong>，对每个原始的子图进行独立解码。</p>
<p>首先，根据任务类型，对批次中的数据进行切片，即通过计算当前图的节点在大图中的切片范围，分离出每一张图。以 TSP 为例，需要对 <code>heatmap</code>、节点特征 <code>x</code> 和 <code>edge_index</code> 进行切片。再调用各个任务子类中定义的 <code>._edge_dense_decode()</code> 方法进行单个实例的解码，结果保存在 <code>solutions</code> 列表中。</p>
<p>如果需要 <code>return_cost</code>，则计算每个实例的成本。对于 TSP 等任务，成本计算比较复杂，我们调用 <code>ml4co_kit</code> 中对应的 <code>Solver</code> 进行计算。最终返回每个实例的成本。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">dense_decode</span>(<span class="hljs-params"></span><br><span class="hljs-params">    self, heatmap: Tensor, task: <span class="hljs-built_in">str</span>, x: Tensor, graph: Tensor,</span><br><span class="hljs-params">    ground_truth: Tensor, nodes_num_list: <span class="hljs-built_in">list</span>, return_cost: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span></span><br><span class="hljs-params"></span>) -&gt; <span class="hljs-type">Union</span>[<span class="hljs-type">List</span>[np.ndarray], np.floating]:<br>    solutions = <span class="hljs-built_in">list</span>()<br>    <span class="hljs-comment"># get solutions</span><br>    <span class="hljs-keyword">if</span> task <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;ATSP&quot;</span>, <span class="hljs-string">&quot;TSP&quot;</span>, <span class="hljs-string">&quot;CVRP&quot;</span>]:<br>        <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(heatmap.shape[<span class="hljs-number">0</span>]):<br>            solutions.append(<span class="hljs-variable language_">self</span>._edge_dense_decode(<br>                heatmap=heatmap[idx], x=x[idx], graph=graph[idx]<br>            ))<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">raise</span> NotImplementedError()<br>    <br>    <span class="hljs-comment"># check if return cost</span><br>    <span class="hljs-keyword">if</span> return_cost:<br>        <span class="hljs-keyword">if</span> task == <span class="hljs-string">&quot;ATSP&quot;</span>:<br>            atsp_solver = ATSPSolver()<br>            atsp_solver.from_data(<br>                dists=to_numpy(graph), tours=solutions<br>            )<br>            costs = atsp_solver.evaluate()<br>        <span class="hljs-keyword">elif</span> task == <span class="hljs-string">&quot;TSP&quot;</span>:<br>            tsp_solver = TSPSolver()<br>            tsp_solver.from_data(<br>                points=to_numpy(x), tours=solutions<br>            )<br>            costs = tsp_solver.evaluate()<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> NotImplementedError()<br>        <span class="hljs-keyword">return</span> costs<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> solutions<br></code></pre></td></tr></table></figure>
<p><code>dense_decode()</code> 方法是稠密图解码调用的外部接口，其作用是<strong>解码一个批次的、以稠密格式表示的数据</strong>。稠密数据在批次维度上是独立的，所以不需要进行复杂的拆分。其余逻辑和 <code>sparse_decode()</code> 方法基本一致。</p>
<h4 id="tsp-py-5"><code>tsp.py</code></h4>
<p>我们以 TSP 为例，看一下具体解码过程的实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">TSPDecoder</span>(<span class="hljs-title class_ inherited__">GNN4CODecoder</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self, </span><br><span class="hljs-params">        decoding_type: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;greedy&quot;</span>, </span><br><span class="hljs-params">        local_search_type: <span class="hljs-built_in">str</span> = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        mcts_time_limit: <span class="hljs-built_in">float</span> = <span class="hljs-number">1.0</span>,</span><br><span class="hljs-params">        mcts_max_depth: <span class="hljs-built_in">int</span> = <span class="hljs-number">10</span>,</span><br><span class="hljs-params">        mcts_type_2opt: <span class="hljs-built_in">int</span> = <span class="hljs-number">2</span></span><br><span class="hljs-params">    </span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-built_in">super</span>(TSPDecoder, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.decoding_type = decoding_type<br>        <span class="hljs-variable language_">self</span>.local_search_type = local_search_type<br>        <span class="hljs-variable language_">self</span>.mcts_time_limit = mcts_time_limit<br>        <span class="hljs-variable language_">self</span>.mcts_max_depth = mcts_max_depth<br>        <span class="hljs-variable language_">self</span>.mcts_type_2opt = mcts_type_2opt<br></code></pre></td></tr></table></figure>
<p><code>TSPDecoder</code> 是对 <code>GNN4CODecoder</code> 类的具体实现，它接收 GNN 模型为<strong>单个 TSP 问题</strong>生成的 heatmap，并根据<strong>选择的解码算法（如贪心、MCTS）和可选的局部搜索方法（如 2-opt）</strong>，构造出高质量的 TSP 路径解。</p>
<p><code>decoding_type</code> 是解码算法，可选 <code>greedy</code>、<code>mcts</code>（蒙特卡洛树搜索） 和 <code>random_mcts</code>。<code>local_search_type</code> 是<strong>改进初始解的局部搜索方法</strong>，可选 <code>mcts</code> 和 <code>2opt</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_edge_sparse_decode</span>(<span class="hljs-params"></span><br><span class="hljs-params">    self, heatmap: Tensor, x: Tensor, edge_index: Tensor, nodes_num: <span class="hljs-built_in">int</span></span><br><span class="hljs-params"></span>) -&gt; np.ndarray:<br>    <span class="hljs-comment"># tensor -&gt; numpy array</span><br>    device = heatmap.device<br>    heatmap = to_numpy(heatmap)<br>    x = to_numpy(x)<br>    edge_index = to_numpy(edge_index)<br><br>    <span class="hljs-comment"># heatmap: sparse -&gt; dense</span><br>    heatmap = np_sparse_to_dense(<br>        nodes_num=nodes_num, edge_index=edge_index, edge_attr=heatmap<br>    )<br>    heatmap = (heatmap + heatmap.T) / <span class="hljs-number">2</span><br>    heatmap = np.clip(heatmap, a_min=<span class="hljs-number">1e-14</span>, a_max=<span class="hljs-number">1</span>-<span class="hljs-number">1e-14</span>)<br>    <br>    <span class="hljs-comment"># decoding</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.decoding_type == <span class="hljs-string">&quot;greedy&quot;</span>:<br>        sol = tsp_greedy_decoder(heatmap)<br>    <span class="hljs-keyword">elif</span> <span class="hljs-variable language_">self</span>.decoding_type == <span class="hljs-string">&quot;mcts&quot;</span>:<br>        sol = tsp_mcts_decoder(<br>            heatmap=heatmap, points=x, time_limit=<span class="hljs-variable language_">self</span>.mcts_time_limit, <br>            max_depth=<span class="hljs-variable language_">self</span>.mcts_max_depth, type_2opt=<span class="hljs-variable language_">self</span>.mcts_type_2opt<br>        )<br>    <span class="hljs-keyword">elif</span> <span class="hljs-variable language_">self</span>.decoding_type == <span class="hljs-string">&quot;random_mcts&quot;</span>:<br>        <span class="hljs-comment"># get solutions</span><br>        sols = <span class="hljs-built_in">list</span>()<br>        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">16</span>):<br>            tour = np.arange(<span class="hljs-number">1</span>, nodes_num)<br>            np.random.shuffle(tour)<br>            tour = np.insert(tour, [<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(tour)], [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>])<br>            sol = tsp_mcts_local_search(<br>                init_tours=tour, <br>                heatmap=heatmap, <br>                points=x, <br>                time_limit=<span class="hljs-variable language_">self</span>.mcts_time_limit, <br>                max_depth=<span class="hljs-variable language_">self</span>.mcts_max_depth, <br>                type_2opt=<span class="hljs-variable language_">self</span>.mcts_type_2opt, <br>                continue_flag=<span class="hljs-number">2</span><br>            )<br>            sols.append(sol)<br>        sol = np.array(sols)<br>        <br>        <span class="hljs-comment"># select best</span><br>        <span class="hljs-built_in">eval</span> = TSPEvaluator(x)<br>        costs = [<span class="hljs-built_in">eval</span>.evaluate(_sol) <span class="hljs-keyword">for</span> _sol <span class="hljs-keyword">in</span> sol]<br>        best_idx = np.argmin(np.array(costs))<br>        sol = sol[best_idx]<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">raise</span> NotImplementedError()<br><br>    <span class="hljs-comment"># local search</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.local_search_type == <span class="hljs-string">&quot;mcts&quot;</span>:<br>        sol = tsp_mcts_local_search(<br>            init_tours=sol, <br>            heatmap=heatmap, <br>            points=x, <br>            time_limit=<span class="hljs-variable language_">self</span>.mcts_time_limit, <br>            max_depth=<span class="hljs-variable language_">self</span>.mcts_max_depth, <br>            type_2opt=<span class="hljs-variable language_">self</span>.mcts_type_2opt, <br>            continue_flag=<span class="hljs-number">2</span><br>        )<br>    <span class="hljs-keyword">elif</span> <span class="hljs-variable language_">self</span>.local_search_type == <span class="hljs-string">&quot;2opt&quot;</span>:<br>        sol = tsp_2opt_local_search(<br>            init_tours=sol, points=x, device=device<br>        )<br>    <span class="hljs-keyword">elif</span> <span class="hljs-variable language_">self</span>.local_search_type <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        <span class="hljs-keyword">raise</span> NotImplementedError()<br>        <br>    <span class="hljs-comment"># return</span><br>    <span class="hljs-keyword">return</span> sol<br></code></pre></td></tr></table></figure>
<p>（此处省略类似的 <code>_edge_dense_decode</code> 函数）</p>
<p><code>_edge_sparse_decode()</code> 方法对单个稀疏图实例进行解码。</p>
<p>首先，将所有输入从 Tensor 转换为 Numpy 数组，因为后续解码和评估都基于 Numpy 实现。调用 <code>np_sparse_to_dense()</code> 函数将 heatmap 从稀疏表示转换为稠密表示，这是<strong>与 <code>_edge_dense_decode()</code> 方法唯一的区别</strong>。<code>heatmap = (heatmap + heatmap.T) / 2</code> 将 heatmap 对称化，因为 TSP 问题是无向的。然后，<code>heatmap = np.clip(...)</code> 对 heatmap 中数值进行裁剪，避免出现 0 或 1 导致后续数值问题。</p>
<p>接着，进行解码。</p>
<ul>
<li><code>greedy</code>：调用 <code>ml4co_kit</code> 中的 <code>tsp_greedy_decoder</code>。这是一种贪心算法，它从一个节点开始，每一步都选择概率最高的、且尚未访问过的邻居，直到所有节点都被访问。</li>
<li><code>mcts</code>：调用 <code>tsp_mcts_decoder</code>。这是一种基于蒙特卡洛树搜索的解码方法。它通过模拟和搜索，能够探索更多的可能性，通常能找到比贪心更好的解，但耗时也更长。</li>
<li><code>random_mcts</code>：这是一种 multi-start 策略。它首先生成 16 个随机的初始路径，然后对每一个随机路径，都使用 MCTS 局部搜索进行优化。最后，它评估这 16 个优化后的解，并返回最好的那一个。</li>
</ul>
<p>然后，进行局部搜索，改进已有的解。</p>
<ul>
<li><code>mcts</code>：对上一步生成的初始解 <code>sol</code>，再次调用 <code>tsp_mcts_local_search</code> 进行优化。</li>
<li><code>2opt</code>：调用 <code>tsp_2opt_local_search</code>。<strong>2-opt 是一种经典的 TSP 局部搜索启发式算法</strong>。它会反复检查路径中是否有交叉的两条边，如果有，就通过交换端点来消除交叉，从而缩短路径长度。</li>
</ul>
<p>最后，返回最终得到的路径。</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/ML4CO/" class="category-chain-item">ML4CO</a>
  
  
    <span>></span>
    
  <a href="/categories/ML4CO/Code-Reading/" class="category-chain-item">Code Reading</a>
  
  

  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/AI/" class="print-no-link">#AI</a>
      
        <a href="/tags/ML4CO/" class="print-no-link">#ML4CO</a>
      
        <a href="/tags/Code-Reading/" class="print-no-link">#Code Reading</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Code Reading #1: GNN4CO</div>
      <div>https://cny123222.github.io/2025/08/24/Code-Reading-1-GNN4CO/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>Nuoyan Chen</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>August 24, 2025</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/08/25/Batch-Layer-or-Instance-Normalization/" title="Batch, Layer, or Instance Normalization?">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Batch, Layer, or Instance Normalization?</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/08/23/Paper-Reading-5-MatNet/" title="Paper Reading #5: MatNet">
                        <span class="hidden-mobile">Paper Reading #5: MatNet</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
    <div id="giscus" class="giscus"></div>
    <script type="text/javascript">
      Fluid.utils.loadComments('#giscus', function() {
        var options = {"repo":"cny123222/cny123222.github.io","repo-id":"R_kgDOOFgnVw","category":"Announcements","category-id":"DIC_kwDOOFgnV84CnwXM","theme-light":"light","theme-dark":"dark","mapping":"pathname","reactions-enabled":1,"emit-metadata":0,"input-position":"top","lang":"en"};
        var attributes = {};
        for (let option in options) {
          if (!option.startsWith('theme-')) {
            var key = option.startsWith('data-') ? option : 'data-' + option;
            attributes[key] = options[option];
          }
        }
        var light = 'light';
        var dark = 'dark';
        window.GiscusThemeLight = light;
        window.GiscusThemeDark = dark;
        attributes['data-theme'] = document.documentElement.getAttribute('data-user-color-scheme') === 'dark' ? dark : light;
        for (let attribute in attributes) {
          var value = attributes[attribute];
          if (value === undefined || value === null || value === '') {
            delete attributes[attribute];
          }
        }
        var s = document.createElement('script');
        s.setAttribute('src', 'https://giscus.app/client.js');
        s.setAttribute('crossorigin', 'anonymous');
        for (let attribute in attributes) {
          s.setAttribute(attribute, attributes[attribute]);
        }
        var ss = document.getElementsByTagName('script');
        var e = ss.length > 0 ? ss[ss.length - 1] : document.head || document.documentElement;
        e.parentNode.insertBefore(s, e.nextSibling);
      });
    </script>
    <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  




  <script>
  Fluid.utils.createScript('https://lib.baomitu.com/mermaid/8.14.0/mermaid.min.js', function() {
    mermaid.initialize({"theme":"default"});

    Fluid.utils.listenDOMLoaded(function() {
      Fluid.events.registerRefreshCallback(function() {
        if ('mermaid' in window) {
          mermaid.init();
        }
      });
    });
  });
</script>






    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        Views: 
        <span id="busuanzi_value_site_pv"></span>
        
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        Visitors: 
        <span id="busuanzi_value_site_uv"></span>
        
      </span>
    
    

  

</div>

  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
